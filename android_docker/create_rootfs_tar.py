#!/usr/bin/env python3
"""
ä½¿ç”¨curlå’ŒPythonåˆ¶ä½œæ ¹æ–‡ä»¶ç³»ç»ŸtaråŒ…çš„è„šæœ¬
ç”¨äºåœ¨Android Termuxä¸­é€šè¿‡prootæ‰§è¡ŒDockeré•œåƒ
æ— éœ€requestsåº“å’Œumociï¼Œåªéœ€è¦curlå‘½ä»¤è¡Œå·¥å…·å’ŒPythonæ ‡å‡†åº“
"""

import os
import sys
import subprocess
import tempfile
import shutil
import argparse
import logging
import json
import hashlib
import tarfile
import gzip
import time
from pathlib import Path
from urllib.parse import urlparse
import platform

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class DockerRegistryClient:
    """Docker Registry APIå®¢æˆ·ç«¯ï¼Œä½¿ç”¨curlä¸‹è½½é•œåƒ"""

    def __init__(self, registry_url, image_name, tag='latest', username=None, password=None, verbose=False):
        self.registry_url = registry_url
        self.image_name = image_name
        self.tag = tag
        self.auth_token = None
        self.user_agent = 'docker-rootfs-creator/1.0'
        self.username = username
        self.password = password
        self.verbose = verbose

    def _run_curl_command(self, cmd, print_cmd=True, show_progress=True):
        """æ‰§è¡Œå¹¶æ‰“å°curlå‘½ä»¤"""
        if print_cmd and self.verbose:
            # ä¸ºäº†å®‰å…¨ï¼Œæ‰“å°å‘½ä»¤æ—¶éšè—å¯†ç 
            safe_cmd = []
            i = 0
            while i < len(cmd):
                safe_cmd.append(cmd[i])
                if cmd[i] == '-u' and i + 1 < len(cmd):
                    safe_cmd.append(f"{cmd[i+1].split(':')[0]}:***")
                    i += 1
                i += 1
            logger.info(f"---\n[ æ‰§è¡Œå‘½ä»¤ ]\n{' '.join(safe_cmd)}\n---")
        
        # æ·»åŠ è¿›åº¦æ¡å‚æ•°
        if show_progress and '-o' in cmd and not self.verbose:
            # æ‰¾åˆ°è¾“å‡ºæ–‡ä»¶å‚æ•°
            try:
                output_idx = cmd.index('-o') + 1
                if output_idx < len(cmd):
                    # æ·»åŠ è¿›åº¦æ¡å‚æ•°
                    cmd.insert(1, '--progress-bar')
            except (ValueError, IndexError):
                pass
        
        try:
            result = subprocess.run(cmd, capture_output=True, text=True, check=True)
            if not result.stdout and not result.stderr:
                # è®°å½•è­¦å‘Šè€Œä¸æ˜¯æŠ›å‡ºå¼‚å¸¸ï¼Œä»¥å¢åŠ ç½‘ç»œå¼¹æ€§
                if self.verbose:
                    logger.warning(f"curlå‘½ä»¤è¿”å›ç©ºå“åº”: {' '.join(cmd)}")
            return result
        except subprocess.CalledProcessError as e:
            logger.error(f"!!! curlå‘½ä»¤æ‰§è¡Œå¤±è´¥ (é”™è¯¯ç : {e.returncode}) !!!")
            if self.verbose:
                logger.error(f"""---
[ é”™è¯¯è¾“å‡º ]
---\n{e.stderr.strip()}""")
            raise

    def _get_auth_token(self, www_authenticate_header):
        """ä»WWW-Authenticateå¤´è·å–è®¤è¯token"""
        if not www_authenticate_header:
            return None

        # è§£æBearer tokenä¿¡æ¯
        if www_authenticate_header.startswith('Bearer '):
            auth_info = {}
            bearer_info = www_authenticate_header[7:]  # ç§»é™¤'Bearer '

            for item in bearer_info.split(','):
                if '=' in item:
                    key, value = item.split('=', 1)
                    auth_info[key.strip()] = value.strip('"')

            if 'realm' in auth_info:
                # æ„å»ºè®¤è¯URL
                auth_url = auth_info['realm']
                params = []
                if 'service' in auth_info:
                    params.append(f"service={auth_info['service']}")
                if 'scope' in auth_info:
                    params.append(f"scope={auth_info['scope']}")

                if params:
                    auth_url += '?' + '&'.join(params)

                # ä½¿ç”¨curlè·å–token
                try:
                    cmd = ['curl', '-v'] # Tokenè·å–ä¸éœ€è¦-i
                    if self.username and self.password:
                        cmd.extend(['-u', f'{self.username}:{self.password}'])
                    cmd.extend(['-H', f'User-Agent: {self.user_agent}', auth_url])
                    
                    # ä¸ºäº†ç®€å•èµ·è§ï¼Œæˆ‘ä»¬ç›´æ¥è°ƒç”¨ï¼Œä¸å†é€šè¿‡_run_curl_command
                    # å› ä¸ºä»£ç†å·²ç»é€šè¿‡ç¯å¢ƒå˜é‡è®¾ç½®
                    if self.verbose:
                        logger.info("""---
[ æ­¥éª¤ 2/3: è·å–è®¤è¯Token ]
---""")
                    else:
                        logger.info("è·å–è®¤è¯Token...")
                    result = self._run_curl_command(cmd, print_cmd=self.verbose)
                    token_data = json.loads(result.stdout)
                    if not self.verbose:
                        logger.info("âœ“ æˆåŠŸè·å–è®¤è¯Token")
                    return token_data.get('token')
                except (subprocess.CalledProcessError, json.JSONDecodeError) as e:
                    logger.warning(f"è·å–è®¤è¯tokenå¤±è´¥: {e}")
                    # åœ¨å¤±è´¥æ—¶æ‰“å°å¯æ‰‹åŠ¨æ‰§è¡Œçš„å‘½ä»¤
                    if isinstance(e, subprocess.CalledProcessError) and self.verbose:
                        logger.warning(f"æ‚¨å¯ä»¥æ‰‹åŠ¨è¿è¡Œä»¥ä¸‹å‘½ä»¤æµ‹è¯•tokenè·å–:\n{' '.join(cmd)}")
                    return None

        return None

    def _make_registry_request(self, path, headers=None, output_file=None):
        """å‘registryå‘é€è¯·æ±‚ï¼Œå¤„ç†è®¤è¯"""
        # æ­¥éª¤1ï¼šå…ˆå‘ä¸€ä¸ªè¯·æ±‚è·å–è®¤è¯å¤´
        if not self.auth_token:
            url = f"{self.registry_url}/v2/{path}"
            cmd = ['curl', '-v', '-i', '--insecure', url]
            if self.verbose:
                logger.info("""---
[ æ­¥éª¤ 1/3: æ¢æµ‹è®¤è¯æœåŠ¡å™¨ ]
---""")
            else:
                logger.info("æ¢æµ‹è®¤è¯æœåŠ¡å™¨...")
            result = self._run_curl_command(cmd, print_cmd=self.verbose)
            
            auth_header = None
            for line in result.stdout.split('\n'):
                if line.lower().startswith('www-authenticate:'):
                    auth_header = line.split(':', 1)[1].strip()
                    break
            
            if auth_header:
                # æ­¥éª¤2ï¼šä½¿ç”¨è®¤è¯å¤´è·å–token
                token = self._get_auth_token(auth_header)
                if token:
                    self.auth_token = token
                    if not self.verbose:
                        logger.info("âœ“ æˆåŠŸè·å–è®¤è¯Token")
                else:
                    logger.warning("æ— æ³•è·å–è®¤è¯tokenï¼Œå°†å°è¯•åŒ¿åè®¿é—®")
            else:
                if self.verbose:
                    logger.info("æ— éœ€è®¤è¯")

        # æ­¥éª¤3ï¼šä½¿ç”¨tokenå‘é€å®é™…è¯·æ±‚
        if self.verbose:
            logger.info("""---
[ æ­¥éª¤ 3/3: è·å–é•œåƒManifest ]
---""")
        
        url = f"{self.registry_url}/v2/{path}"
        cmd = ['curl', '-v', '-i', '--insecure', '-H', f'User-Agent: {self.user_agent}']
        
        # æ·»åŠ Acceptå¤´
        if headers and 'Accept' in headers:
            cmd.extend(['-H', f"Accept: {headers['Accept']}"])
        
        # å¦‚æœæœ‰è®¤è¯tokenï¼Œæ·»åŠ Authorizationå¤´
        if self.auth_token:
            cmd.extend(['-H', f'Authorization: Bearer {self.auth_token}'])
        
        cmd.append(url)
        
        result = self._run_curl_command(cmd, print_cmd=self.verbose)
        
        # è§£æå“åº”
        lines = result.stdout.split('\n')
        status_line = None
        response_headers = {}
        body_start = 0
        header_section = True
        
        for i, line in enumerate(lines):
            if line.startswith('HTTP/'):
                status_line = line
                header_section = True
                continue
            elif header_section and line.strip() == '':
                # ç©ºè¡Œè¡¨ç¤ºå¤´éƒ¨ç»“æŸï¼Œæ¥ä¸‹æ¥æ˜¯å“åº”ä½“
                body_start = i + 1
                header_section = False
                break
            elif header_section and ':' in line:
                key, value = line.split(':', 1)
                response_headers[key.strip().lower()] = value.strip()

        # æå–çŠ¶æ€ç 
        status_code = 200  # é»˜è®¤å€¼
        if status_line:
            try:
                status_code = int(status_line.split()[1])
            except (IndexError, ValueError):
                pass

        # æå–å“åº”ä½“ - è·³è¿‡curlçš„è°ƒè¯•è¾“å‡º
        body_lines = []
        for i in range(body_start, len(lines)):
            line = lines[i]
            # è·³è¿‡curlçš„è°ƒè¯•ä¿¡æ¯è¡Œ
            if line.startswith('* ') or line.startswith('> ') or line.startswith('< '):
                continue
            body_lines.append(line)
        
        body = '\n'.join(body_lines).strip()

        if status_code >= 400:
            raise Exception(f"HTTP {status_code}: {body}")

        return {
            'status_code': status_code,
            'headers': response_headers,
            'body': body
        }

    def get_manifest(self):
        """è·å–é•œåƒmanifest"""
        if self.verbose:
            logger.info(f"è·å–é•œåƒmanifest: {self.image_name}:{self.tag}")
        else:
            logger.info(f"è·å–é•œåƒä¿¡æ¯: {self.image_name}:{self.tag}")

        # æ”¯æŒå¤šç§manifestæ ¼å¼
        accept_headers = [
            'application/vnd.docker.distribution.manifest.v2+json',
            'application/vnd.docker.distribution.manifest.list.v2+json',
            'application/vnd.oci.image.manifest.v1+json',
            'application/vnd.oci.image.index.v1+json'
        ]

        headers = {
            'Accept': ', '.join(accept_headers)
        }

        path = f"{self.image_name}/manifests/{self.tag}"
        response = self._make_registry_request(path, headers)

        try:
            # æ·»åŠ è°ƒè¯•ä¿¡æ¯
            if self.verbose:
                logger.debug(f"Response body (first 200 chars): {response['body'][:200]}")
                logger.debug(f"Response headers: {response['headers']}")
            
            # æ¸…ç†å“åº”ä½“ - ç§»é™¤å¯èƒ½çš„å¤šä½™ç©ºè¡Œå’Œcurlè¾“å‡º
            body = response['body'].strip()
            if not body:
                raise ValueError("å“åº”ä½“ä¸ºç©º")
            
            # å°è¯•æ‰¾åˆ°JSONçš„å¼€å§‹ä½ç½®
            json_start = body.find('{')
            if json_start == -1:
                json_start = body.find('[')
            
            if json_start > 0:
                body = body[json_start:]
                if self.verbose:
                    logger.debug(f"Cleaned body (first 200 chars): {body[:200]}")
            
            manifest = json.loads(body)
            content_type = response['headers'].get('content-type', '')
        except json.JSONDecodeError as e:
            logger.error(f"JSONè§£æå¤±è´¥: {e}")
            logger.error(f"å“åº”ä½“å†…å®¹: {response['body'][:500]}")
            logger.error(f"å“åº”å¤´: {response['headers']}")
            raise

        if self.verbose:
            logger.info(f"Manifestç±»å‹: {content_type}")
        return manifest, content_type

    def download_blob(self, digest, output_path):
        """ä¸‹è½½blobåˆ°æŒ‡å®šè·¯å¾„"""
        if self.verbose:
            logger.info(f"ä¸‹è½½blob: {digest}")
        else:
            # æ˜¾ç¤ºç®€åŒ–çš„ä¸‹è½½ä¿¡æ¯
            blob_name = digest.split(':')[-1][:12]  # æ˜¾ç¤ºå‰12ä½
            logger.info(f"ä¸‹è½½: {blob_name}...")

        path = f"{self.image_name}/blobs/{digest}"

        # ç›´æ¥ä¸‹è½½åˆ°æ–‡ä»¶
        cmd = ['curl', '-v', '-L', '-H', f'User-Agent: {self.user_agent}']

        # å¦‚æœæœ‰è®¤è¯tokenï¼Œæ·»åŠ Authorizationå¤´
        if self.auth_token:
            cmd.extend(['-H', f'Authorization: Bearer {self.auth_token}'])

        url = f"{self.registry_url}/v2/{path}"
        cmd.extend(['-o', output_path, url])

        self._run_curl_command(cmd, print_cmd=self.verbose, show_progress=not self.verbose)

        if not self.verbose:
            logger.info("âœ“ ä¸‹è½½å®Œæˆ")
        return output_path

class DockerImageToRootFS:
    def __init__(self, image_url, output_path=None, username=None, password=None, architecture=None, verbose=False, quiet=False):
        self.image_url = image_url
        self.output_path = output_path or f"{self._get_image_name()}_rootfs.tar"
        self.temp_dir = None
        self.username = username
        self.password = password
        self.architecture = architecture or self._get_current_architecture()
        self.verbose = verbose
        self.quiet = quiet
        if not quiet:
            logger.info(f"ç›®æ ‡æ¶æ„: {self.architecture}")
        
    def _get_current_architecture(self):
        """è·å–å½“å‰ç³»ç»Ÿçš„æ¶æ„"""
        machine = platform.machine().lower()
        if machine in ['x86_64', 'amd64']:
            return 'amd64'
        elif machine in ['aarch64', 'arm64']:
            return 'arm64'
        elif machine.startswith('armv'):
            return 'arm'
        elif machine in ['i386', 'i686']:
            return '386'
        else:
            logger.warning(f"æ— æ³•è¯†åˆ«çš„æ¶æ„: {machine}, å°†é»˜è®¤ä½¿ç”¨ amd64")
            return 'amd64'

    def _get_image_name(self):
        """ä»é•œåƒURLä¸­æå–é•œåƒåç§°"""
        # ä»URLä¸­æå–é•œåƒåç§°ï¼Œå»æ‰åŸŸåå’Œæ ‡ç­¾
        parts = self.image_url.split('/')
        image_name = parts[-1].split(':')[0]
        return image_name
    
    def _check_dependencies(self):
        """æ£€æŸ¥curlæ˜¯å¦å·²å®‰è£…"""
        # æ£€æŸ¥curl
        try:
            subprocess.run(['curl', '--version'],
                         capture_output=True, check=True)
            logger.info("âœ“ curl å·²å®‰è£…")
        except (subprocess.CalledProcessError, FileNotFoundError):
            logger.error("âœ— curl æœªå®‰è£…")
            logger.info("è¯·å®‰è£…curlå‘½ä»¤è¡Œå·¥å…·")
            return False

        # æ£€æŸ¥tarå‘½ä»¤
        try:
            subprocess.run(['tar', '--version'],
                         capture_output=True, check=True)
            logger.info("âœ“ tar å·²å®‰è£…")
        except (subprocess.CalledProcessError, FileNotFoundError):
            logger.error("âœ— tar æœªå®‰è£…")
            logger.info("è¯·å®‰è£…tarå‘½ä»¤è¡Œå·¥å…·")
            return False

        return True
    
    def _run_command(self, cmd, cwd=None):
        """æ‰§è¡Œå‘½ä»¤å¹¶å¤„ç†é”™è¯¯"""
        logger.info(f"æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
        try:
            result = subprocess.run(
                cmd, 
                cwd=cwd,
                capture_output=True, 
                text=True, 
                check=True
            )
            if result.stdout:
                logger.debug(f"è¾“å‡º: {result.stdout}")
            return result
        except subprocess.CalledProcessError as e:
            logger.error(f"å‘½ä»¤æ‰§è¡Œå¤±è´¥: {' '.join(cmd)}")
            logger.error(f"é”™è¯¯ç : {e.returncode}")
            logger.error(f"é”™è¯¯è¾“å‡º: {e.stderr}")
            raise
    
    def _create_temp_directory(self):
        """åˆ›å»ºä¸´æ—¶å·¥ä½œç›®å½•"""
        self.temp_dir = tempfile.mkdtemp(prefix='docker_rootfs_')
        logger.info(f"åˆ›å»ºä¸´æ—¶ç›®å½•: {self.temp_dir}")
        return self.temp_dir
    
    def _cleanup_temp_directory(self):
        """æ¸…ç†ä¸´æ—¶ç›®å½•"""
        if self.temp_dir and os.path.exists(self.temp_dir):
            # shutil.rmtree(self.temp_dir)
            logger.info(f"æ¸…ç†ä¸´æ—¶ç›®å½•: {self.temp_dir}")

    def _parse_image_url(self):
        """è§£æé•œåƒURLï¼Œæå–registryã€é•œåƒåå’Œæ ‡ç­¾"""
        image_url = self.image_url

        # é»˜è®¤å€¼
        registry = "registry-1.docker.io"
        image_name = ""
        tag = "latest"

        # ç§»é™¤docker://å‰ç¼€ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if image_url.startswith('docker://'):
            image_url = image_url[9:]

        # åˆ†ç¦»æ ‡ç­¾
        # æ”¹è¿›çš„æ ‡ç­¾åˆ†ç¦»é€»è¾‘
        if ':' in image_url:
            # æ£€æŸ¥å†’å·æ˜¯å¦åœ¨æœ€åä¸€ä¸ªæ–œæ ä¹‹åï¼Œæˆ–è€…æ ¹æœ¬æ²¡æœ‰æ–œæ 
            last_colon = image_url.rfind(':')
            last_slash = image_url.rfind('/')
            if last_colon > last_slash:
                # é€‚ç”¨äº a/b:tag, a:123/b:tag, a:tag
                image_url, tag = image_url.rsplit(':', 1)

        # åˆ†ç¦»registryå’Œé•œåƒå
        if '/' in image_url:
            parts = image_url.split('/', 1)
            if '.' in parts[0] or ':' in parts[0]:  # åŒ…å«åŸŸå
                registry = parts[0]
                image_name = parts[1]
            else:  # Docker Hubçš„ç®€å†™å½¢å¼
                registry = "registry-1.docker.io"
                image_name = image_url
                # Docker Hubçš„libraryé•œåƒéœ€è¦æ·»åŠ library/å‰ç¼€
                if '/' not in image_name:
                    image_name = f"library/{image_name}"
        else:
            # åªæœ‰é•œåƒåï¼Œä½¿ç”¨Docker Hub
            registry = "registry-1.docker.io"
            image_name = f"library/{image_url}"

        # ç¡®ä¿registryæœ‰åè®®å‰ç¼€
        if not registry.startswith(('http://', 'https://')):
            registry = f"https://{registry}"

        logger.info(f"è§£æé•œåƒURL: registry={registry}, image={image_name}, tag={tag}")
        return registry, image_name, tag
    
    def _download_image_with_python(self):
        """ä½¿ç”¨Pythonä¸‹è½½Dockeré•œåƒåˆ°OCIæ ¼å¼"""
        oci_dir = os.path.join(self.temp_dir, 'oci')
        os.makedirs(oci_dir, exist_ok=True)

        # è§£æé•œåƒURL
        registry, image_name, tag = self._parse_image_url()

        # åˆ›å»ºregistryå®¢æˆ·ç«¯
        client = DockerRegistryClient(registry, image_name, tag, self.username, self.password, self.verbose)

        # è·å–manifest
        manifest, content_type = client.get_manifest()

        # å¦‚æœæ˜¯manifest listï¼Œæ ¹æ®æ¶æ„é€‰æ‹©ä¸€ä¸ªå…·ä½“çš„manifest
        if 'manifest.list' in content_type or 'image.index' in content_type:
            logger.info("æ£€æµ‹åˆ°manifest listï¼Œæ­£åœ¨å¯»æ‰¾åŒ¹é…çš„æ¶æ„...")
            
            selected_manifest_descriptor = None
            for manifest_descriptor in manifest.get('manifests', []):
                platform_info = manifest_descriptor.get('platform', {})
                if platform_info.get('architecture') == self.architecture:
                    # ä¼˜å…ˆé€‰æ‹©ä¸OSåŒ¹é…çš„ï¼Œå¦‚æœæ²¡æœ‰oså­—æ®µåˆ™ç›´æ¥åŒ¹é…
                    if platform_info.get('os') == 'linux' or 'os' not in platform_info:
                        selected_manifest_descriptor = manifest_descriptor
                        break
            
            if selected_manifest_descriptor:
                target_digest = selected_manifest_descriptor['digest']
                logger.info(f"æ‰¾åˆ°åŒ¹é…æ¶æ„ '{self.architecture}' çš„manifest: {target_digest}")
                
                # è·å–å­manifest
                logger.info(f"""---
[ æ­¥éª¤ 3/3: è·å–é•œåƒManifest ]
---""")
                response = client._make_registry_request(f"{client.image_name}/manifests/{target_digest}")
                manifest = json.loads(response['body'])
                content_type = response['headers'].get('content-type', '') # æ›´æ–°content_type
                logger.info(f"å·²é€‰æ‹©å­manifestï¼Œç±»å‹: {content_type}")
            else:
                available_archs = [m.get('platform', {}).get('architecture') for m in manifest.get('manifests', [])]
                raise ValueError(f"åœ¨manifest listä¸­æ‰¾ä¸åˆ°é€‚ç”¨äºæ¶æ„ '{self.architecture}' çš„é•œåƒã€‚å¯ç”¨æ¶æ„: {available_archs}")

        # åˆ›å»ºOCIç›®å½•ç»“æ„
        blobs_dir = os.path.join(oci_dir, 'blobs', 'sha256')
        os.makedirs(blobs_dir, exist_ok=True)

        # ä¿å­˜manifest
        manifest_digest = self._save_manifest(oci_dir, manifest, content_type)

        # ä¸‹è½½æ‰€æœ‰å±‚å’Œconfig
        self._download_layers(client, manifest, blobs_dir)

        # è½¬æ¢config blobä¸ºOCIæ ¼å¼
        if 'config' in manifest:
            self._convert_config_blob(client, manifest['config'], blobs_dir)

        # åˆ›å»ºoci-layoutæ–‡ä»¶
        self._create_oci_layout(oci_dir)

        # åˆ›å»ºindex.json
        self._create_oci_index(oci_dir, manifest_digest, content_type)

        logger.info(f"é•œåƒå·²ä¸‹è½½åˆ°OCIæ ¼å¼: {oci_dir}")
        return oci_dir

    def _save_manifest(self, oci_dir, manifest, content_type):
        """ä¿å­˜manifestå¹¶è¿”å›å…¶digestï¼Œè½¬æ¢ä¸ºOCIæ ¼å¼"""
        # è½¬æ¢Dockeræ ¼å¼çš„manifestä¸ºOCIæ ¼å¼
        oci_manifest = self._convert_manifest_to_oci(manifest, content_type)

        manifest_json = json.dumps(oci_manifest, separators=(',', ':'))
        manifest_bytes = manifest_json.encode('utf-8')

        # è®¡ç®—digest
        digest = hashlib.sha256(manifest_bytes).hexdigest()

        # ä¿å­˜åˆ°blobsç›®å½•
        blobs_dir = os.path.join(oci_dir, 'blobs', 'sha256')
        manifest_path = os.path.join(blobs_dir, digest)

        with open(manifest_path, 'wb') as f:
            f.write(manifest_bytes)

        logger.debug(f"OCI Manifestå·²ä¿å­˜: sha256:{digest}")
        return f"sha256:{digest}"

    def _convert_manifest_to_oci(self, manifest, content_type):
        """å°†Docker manifestè½¬æ¢ä¸ºOCIæ ¼å¼"""
        if 'docker' not in content_type:
            # å·²ç»æ˜¯OCIæ ¼å¼
            return manifest

        oci_manifest = manifest.copy()

        # è½¬æ¢åª’ä½“ç±»å‹
        if 'layers' in oci_manifest:
            for layer in oci_manifest['layers']:
                if layer.get('mediaType') == 'application/vnd.docker.image.rootfs.diff.tar.gzip':
                    layer['mediaType'] = 'application/vnd.oci.image.layer.v1.tar+gzip'
                elif layer.get('mediaType') == 'application/vnd.docker.image.rootfs.diff.tar':
                    layer['mediaType'] = 'application/vnd.oci.image.layer.v1.tar'

        if 'config' in oci_manifest:
            if oci_manifest['config'].get('mediaType') == 'application/vnd.docker.container.image.v1+json':
                oci_manifest['config']['mediaType'] = 'application/vnd.oci.image.config.v1+json'

        # è®¾ç½®æ­£ç¡®çš„åª’ä½“ç±»å‹
        oci_manifest['mediaType'] = 'application/vnd.oci.image.manifest.v1+json'

        logger.debug("å·²å°†Docker manifestè½¬æ¢ä¸ºOCIæ ¼å¼")
        return oci_manifest

    def _convert_config_blob(self, client, config_descriptor, blobs_dir):
        """è½¬æ¢config blobä¸ºOCIæ ¼å¼"""
        digest = config_descriptor['digest']

        if digest.startswith('sha256:'):
            digest_hash = digest[7:]
        else:
            digest_hash = digest

        config_path = os.path.join(blobs_dir, digest_hash)

        # è¯»å–åŸå§‹config
        if not os.path.exists(config_path):
            logger.error(f"Config blobä¸å­˜åœ¨: {config_path}")
            return

        try:
            with open(config_path, 'r') as f:
                config_data = json.load(f)

            # è½¬æ¢Docker configä¸ºOCI config
            oci_config = self._convert_docker_config_to_oci(config_data)

            # é‡æ–°ä¿å­˜è½¬æ¢åçš„config
            with open(config_path, 'w') as f:
                json.dump(oci_config, f, separators=(',', ':'))

            logger.debug(f"å·²è½¬æ¢config blobä¸ºOCIæ ¼å¼: {digest}")

        except Exception as e:
            logger.warning(f"è½¬æ¢config blobå¤±è´¥: {e}")

    def _convert_docker_config_to_oci(self, docker_config):
        """å°†Docker configè½¬æ¢ä¸ºOCI config"""
        oci_config = docker_config.copy()

        # OCI configçš„åŸºæœ¬ç»“æ„ä¸Docker configç±»ä¼¼ï¼Œä½†æœ‰ä¸€äº›å­—æ®µå·®å¼‚
        # ä¸»è¦æ˜¯ç¡®ä¿å¿…è¦çš„å­—æ®µå­˜åœ¨

        if 'architecture' not in oci_config:
            oci_config['architecture'] = 'amd64'

        if 'os' not in oci_config:
            oci_config['os'] = 'linux'

        # ç¡®ä¿configå­—æ®µå­˜åœ¨
        if 'config' not in oci_config:
            oci_config['config'] = {}

        # ç¡®ä¿rootfså­—æ®µå­˜åœ¨
        if 'rootfs' not in oci_config:
            oci_config['rootfs'] = {
                'type': 'layers',
                'diff_ids': []
            }

        # ç¡®ä¿historyå­—æ®µå­˜åœ¨
        if 'history' not in oci_config:
            oci_config['history'] = []

        return oci_config

    def _download_layers(self, client, manifest, blobs_dir):
        """ä¸‹è½½é•œåƒçš„æ‰€æœ‰å±‚"""
        # å¤„ç†ä¸åŒç±»å‹çš„manifest
        layers = []

        if 'layers' in manifest and manifest['layers']:
            # Docker v2 manifest æˆ– OCI manifest
            layers = manifest['layers'][:]
            if 'config' in manifest:
                layers.append(manifest['config'])
        elif 'fsLayers' in manifest and manifest['fsLayers']:
            # Docker v1 manifest (å·²åºŸå¼ƒï¼Œä½†ä»éœ€æ”¯æŒ)
            layers = manifest['fsLayers'][:]
            if 'history' in manifest:
                # v1 manifestçš„configä¿¡æ¯åœ¨historyä¸­
                pass
        # manifest list çš„å¤„ç†å·²ç§»åˆ°è°ƒç”¨æ–¹
        elif not layers:
            raise ValueError("Manifestä¸­æ²¡æœ‰æ‰¾åˆ°'layers'æˆ–'fsLayers'å­—æ®µï¼Œæˆ–è€…å®ƒä»¬ä¸ºç©º")

        for layer in layers:
            digest = layer.get('digest') or layer.get('blobSum')
            if digest:
                # ç§»é™¤sha256:å‰ç¼€ç”¨äºæ–‡ä»¶å
                if digest.startswith('sha256:'):
                    digest_hash = digest[7:]
                else:
                    digest_hash = digest

                blob_path = os.path.join(blobs_dir, digest_hash)
                if not os.path.exists(blob_path):
                    try:
                        client.download_blob(digest, blob_path)
                        logger.debug(f"å·²ä¸‹è½½å±‚: {digest}")
                    except Exception as e:
                        logger.error(f"ä¸‹è½½å±‚å¤±è´¥ {digest}: {e}")
                        raise

    def _create_oci_index(self, oci_dir, manifest_digest, content_type):
        """åˆ›å»ºOCI index.jsonæ–‡ä»¶"""
        # ç¡®ä¿content_typeç¬¦åˆOCIè§„èŒƒ
        if 'docker' in content_type:
            # å°†Dockeræ ¼å¼è½¬æ¢ä¸ºOCIæ ¼å¼
            if 'manifest.v2+json' in content_type:
                oci_content_type = "application/vnd.oci.image.manifest.v1+json"
            elif 'manifest.list.v2+json' in content_type:
                oci_content_type = "application/vnd.oci.image.index.v1+json"
            else:
                oci_content_type = content_type
        else:
            oci_content_type = content_type

        # è·å–manifestæ–‡ä»¶å¤§å°
        manifest_file_path = os.path.join(oci_dir, 'blobs', 'sha256', manifest_digest[7:])
        manifest_size = os.path.getsize(manifest_file_path) if os.path.exists(manifest_file_path) else 0

        index = {
            "schemaVersion": 2,
            "manifests": [
                {
                    "mediaType": oci_content_type,
                    "digest": manifest_digest,
                    "size": manifest_size,
                    "annotations": {
                        "org.opencontainers.image.ref.name": "latest"
                    }
                }
            ]
        }

        index_path = os.path.join(oci_dir, 'index.json')
        with open(index_path, 'w') as f:
            json.dump(index, f, indent=2)

        logger.debug(f"OCI indexå·²åˆ›å»º: {index_path}")
        logger.debug(f"ä½¿ç”¨content type: {oci_content_type}")

    def _create_oci_layout(self, oci_dir):
        """åˆ›å»ºoci-layoutæ–‡ä»¶"""
        layout = {
            "imageLayoutVersion": "1.0.0"
        }

        layout_path = os.path.join(oci_dir, 'oci-layout')
        with open(layout_path, 'w') as f:
            json.dump(layout, f, indent=2)

        logger.debug(f"OCI layoutå·²åˆ›å»º: {layout_path}")

    def _save_image_config(self, oci_dir, rootfs_dir):
        """ä¿å­˜é•œåƒé…ç½®åˆ°æ ¹æ–‡ä»¶ç³»ç»Ÿä¸­ï¼Œä¾›proot_runnerä½¿ç”¨"""
        try:
            # è¯»å–OCI index
            index_path = os.path.join(oci_dir, 'index.json')
            with open(index_path, 'r') as f:
                index = json.load(f)

            # è·å–manifest
            manifest_descriptor = index['manifests'][0]
            manifest_digest = manifest_descriptor['digest']
            manifest_path = os.path.join(oci_dir, 'blobs', 'sha256', manifest_digest[7:])

            with open(manifest_path, 'r') as f:
                manifest = json.load(f)

            # è·å–config
            if 'config' in manifest:
                config_digest = manifest['config']['digest']
                config_path = os.path.join(oci_dir, 'blobs', 'sha256', config_digest[7:])

                if os.path.exists(config_path):
                    with open(config_path, 'r') as f:
                        config_data = json.load(f)

                    # ä¿å­˜é…ç½®åˆ°æ ¹æ–‡ä»¶ç³»ç»Ÿ
                    config_save_path = os.path.join(rootfs_dir, '.image_config.json')
                    with open(config_save_path, 'w') as f:
                        json.dump(config_data, f, indent=2)

                    logger.info(f"é•œåƒé…ç½®å·²ä¿å­˜åˆ°: {config_save_path}")

                    # æ˜¾ç¤ºä¸€äº›æœ‰ç”¨çš„ä¿¡æ¯
                    config = config_data.get('config', {})
                    if 'Cmd' in config:
                        logger.info(f"é»˜è®¤å‘½ä»¤: {config['Cmd']}")
                    if 'Entrypoint' in config:
                        logger.info(f"å…¥å£ç‚¹: {config['Entrypoint']}")
                    if 'WorkingDir' in config:
                        logger.info(f"å·¥ä½œç›®å½•: {config['WorkingDir']}")
                    if 'Env' in config:
                        logger.info(f"ç¯å¢ƒå˜é‡: {len(config['Env'])} ä¸ª")
                else:
                    logger.warning("æœªæ‰¾åˆ°config blob")
            else:
                logger.warning("manifestä¸­æ²¡æœ‰configä¿¡æ¯")

        except Exception as e:
            logger.warning(f"ä¿å­˜é•œåƒé…ç½®å¤±è´¥: {e}")
            # ä¸å½±å“ä¸»è¦æµç¨‹ï¼Œç»§ç»­æ‰§è¡Œ
    
    def _extract_rootfs_with_python(self, oci_dir):
        """ä½¿ç”¨Pythonæå–æ ¹æ–‡ä»¶ç³»ç»Ÿ"""
        rootfs_dir = os.path.join(self.temp_dir, 'rootfs')
        os.makedirs(rootfs_dir, exist_ok=True)

        # è¯»å–OCI index
        index_path = os.path.join(oci_dir, 'index.json')
        with open(index_path, 'r') as f:
            index = json.load(f)

        # è·å–manifest
        manifest_descriptor = index['manifests'][0]
        manifest_digest = manifest_descriptor['digest']
        manifest_path = os.path.join(oci_dir, 'blobs', 'sha256', manifest_digest[7:])

        with open(manifest_path, 'r') as f:
            manifest = json.load(f)

        logger.info(f"å¼€å§‹æå– {len(manifest.get('layers', []))} ä¸ªå±‚")

        # æå–æ‰€æœ‰å±‚
        layers = manifest.get('layers', [])
        for i, layer in enumerate(layers, 1):
            layer_digest = layer['digest']
            layer_path = os.path.join(oci_dir, 'blobs', 'sha256', layer_digest[7:])

            logger.info(f"æå–å±‚ {i}/{len(layers)}: {layer_digest}")

            # ç¬¬ä¸€å±‚ä½¿ç”¨ä¸¥æ ¼æ¨¡å¼ï¼Œåç»­å±‚ä½¿ç”¨å®½æ¾æ¨¡å¼
            is_first_layer = (i == 1)
            self._extract_layer(layer_path, rootfs_dir, is_first_layer)

        logger.info(f"æ ¹æ–‡ä»¶ç³»ç»Ÿå·²æå–åˆ°: {rootfs_dir}")
        return rootfs_dir

    def _extract_layer(self, layer_path, rootfs_dir, is_first_layer=False):
        """æå–å•ä¸ªå±‚åˆ°æ ¹æ–‡ä»¶ç³»ç»Ÿç›®å½•"""
        # åœ¨Androidç¯å¢ƒä¸­ä¼˜å…ˆä½¿ç”¨tarå‘½ä»¤ï¼Œå› ä¸ºå®ƒå¯¹ç¡¬é“¾æ¥å¤„ç†æ›´å¥½
        if self._is_android_environment():
            try:
                self._extract_layer_with_tar(layer_path, rootfs_dir, is_first_layer)
                return
            except Exception as e:
                logger.warning(f"tarå‘½ä»¤æå–å¤±è´¥: {e}")
                logger.info("å°è¯•ä½¿ç”¨Python tarfileæ¨¡å—...")

        try:
            # ä½¿ç”¨Pythonçš„tarfileæ¨¡å—
            self._extract_layer_with_python(layer_path, rootfs_dir)
        except Exception as e:
            logger.warning(f"Python tarfileæå–å¤±è´¥: {e}")
            # å¦‚æœè¿˜æ²¡è¯•è¿‡tarå‘½ä»¤ï¼Œç°åœ¨è¯•è¯•
            if not self._is_android_environment():
                self._extract_layer_with_tar(layer_path, rootfs_dir, is_first_layer)

    def _extract_layer_with_python(self, layer_path, rootfs_dir):
        """ä½¿ç”¨Python tarfileæ¨¡å—æå–å±‚"""
        import tarfile
        import gzip

        # æ£€æµ‹æ–‡ä»¶ç±»å‹
        with open(layer_path, 'rb') as f:
            magic = f.read(2)

        try:
            if magic == b'\x1f\x8b':  # gzip magic number
                # è¿™æ˜¯ä¸€ä¸ªgzipå‹ç¼©çš„taræ–‡ä»¶
                with gzip.open(layer_path, 'rb') as gz_file:
                    with tarfile.open(fileobj=gz_file, mode='r|*') as tar:
                        self._safe_extract_tar(tar, rootfs_dir)
            else:
                # å°è¯•ä½œä¸ºæ™®é€štaræ–‡ä»¶
                with tarfile.open(layer_path, 'r') as tar:
                    self._safe_extract_tar(tar, rootfs_dir)
        except Exception as e:
            # å¦‚æœæµå¼è¯»å–å¤±è´¥ï¼Œå°è¯•éæµå¼
            logger.debug(f"æµå¼æå–å¤±è´¥ï¼Œå°è¯•éæµå¼: {e}")
            if magic == b'\x1f\x8b':
                with tarfile.open(layer_path, 'r:gz') as tar:
                    self._safe_extract_tar(tar, rootfs_dir)
            else:
                with tarfile.open(layer_path, 'r') as tar:
                    self._safe_extract_tar(tar, rootfs_dir)

    def _safe_extract_tar(self, tar, rootfs_dir):
        """å®‰å…¨åœ°æå–taræ–‡ä»¶ï¼Œå¤„ç†ç‰¹æ®Šæƒ…å†µ"""
        # è®¾ç½®æå–è¿‡æ»¤å™¨ä»¥é¿å…è­¦å‘Š
        def extract_filter(member, path):
            # è·³è¿‡è®¾å¤‡æ–‡ä»¶å’Œç‰¹æ®Šæ–‡ä»¶
            if member.isdev() or member.isfifo():
                logger.debug(f"è·³è¿‡è®¾å¤‡/FIFOæ–‡ä»¶: {member.name}")
                return None

            # å¤„ç†è·¯å¾„å®‰å…¨æ€§
            if member.name.startswith('/') or '..' in member.name:
                logger.warning(f"è·³è¿‡ä¸å®‰å…¨çš„è·¯å¾„: {member.name}")
                return None

            # åœ¨Androidç¯å¢ƒä¸­ï¼Œé‡ç½®æƒé™ä»¥é¿å…é—®é¢˜
            if self._is_android_environment():
                if member.isfile():
                    member.mode = 0o644
                elif member.isdir():
                    member.mode = 0o755
                # é‡ç½®æ‰€æœ‰è€…ä¿¡æ¯
                member.uid = 0
                member.gid = 0
                member.uname = 'root'
                member.gname = 'root'

            return member

        # æ‰‹åŠ¨å¤„ç†æ¯ä¸ªæˆå‘˜ï¼Œæ›´å¥½åœ°æ§åˆ¶æå–è¿‡ç¨‹
        for member in tar:
            try:
                # åº”ç”¨è¿‡æ»¤å™¨
                filtered_member = extract_filter(member, rootfs_dir)
                if not filtered_member:
                    continue

                # ç‰¹æ®Šå¤„ç†ç¡¬é“¾æ¥
                if member.islnk():
                    # å°†ç¡¬é“¾æ¥è½¬æ¢ä¸ºæ™®é€šæ–‡ä»¶æˆ–ç¬¦å·é“¾æ¥
                    self._handle_hardlink(tar, member, rootfs_dir)
                    continue

                # æ­£å¸¸æå–
                tar.extract(filtered_member, rootfs_dir)

            except (OSError, PermissionError, tarfile.ExtractError) as e:
                logger.debug(f"æå–æ–‡ä»¶å¤±è´¥ {member.name}: {e}")

                # å°è¯•æ‰‹åŠ¨åˆ›å»ºæ–‡ä»¶
                if member.isfile():
                    self._manual_extract_file(tar, member, rootfs_dir)
                elif member.isdir():
                    self._manual_create_dir(member, rootfs_dir)
                elif member.islnk():
                    self._handle_hardlink(tar, member, rootfs_dir)
                elif member.issym():
                    self._manual_create_symlink(member, rootfs_dir)

    def _handle_hardlink(self, tar, member, rootfs_dir):
        """å¤„ç†ç¡¬é“¾æ¥ï¼Œè½¬æ¢ä¸ºæ™®é€šæ–‡ä»¶"""
        try:
            target_path = os.path.join(rootfs_dir, member.name)
            link_target_path = os.path.join(rootfs_dir, member.linkname)

            # å¦‚æœé“¾æ¥ç›®æ ‡å­˜åœ¨ï¼Œå¤åˆ¶æ–‡ä»¶å†…å®¹
            if os.path.exists(link_target_path):
                os.makedirs(os.path.dirname(target_path), exist_ok=True)
                shutil.copy2(link_target_path, target_path)
                logger.debug(f"ç¡¬é“¾æ¥è½¬æ¢ä¸ºæ–‡ä»¶å‰¯æœ¬: {member.name} -> {member.linkname}")
            else:
                # å¦‚æœç›®æ ‡ä¸å­˜åœ¨ï¼Œå°è¯•ä»tarä¸­æå–åŸå§‹æ–‡ä»¶
                logger.debug(f"ç¡¬é“¾æ¥ç›®æ ‡ä¸å­˜åœ¨ï¼Œè·³è¿‡: {member.name} -> {member.linkname}")
        except Exception as e:
            logger.debug(f"å¤„ç†ç¡¬é“¾æ¥å¤±è´¥ {member.name}: {e}")

    def _manual_extract_file(self, tar, member, rootfs_dir):
        """æ‰‹åŠ¨æå–æ–‡ä»¶"""
        try:
            target_path = os.path.join(rootfs_dir, member.name)
            os.makedirs(os.path.dirname(target_path), exist_ok=True)

            with open(target_path, 'wb') as target_file:
                source_file = tar.extractfile(member)
                if source_file:
                    shutil.copyfileobj(source_file, target_file)

            # è®¾ç½®åŸºæœ¬æƒé™
            try:
                os.chmod(target_path, 0o644 if not (member.mode & 0o111) else 0o755)
            except OSError:
                pass

        except Exception as e:
            logger.debug(f"æ‰‹åŠ¨æå–æ–‡ä»¶å¤±è´¥ {member.name}: {e}")

    def _manual_create_dir(self, member, rootfs_dir):
        """æ‰‹åŠ¨åˆ›å»ºç›®å½•"""
        try:
            target_path = os.path.join(rootfs_dir, member.name)
            os.makedirs(target_path, exist_ok=True)
            try:
                os.chmod(target_path, 0o755)
            except OSError:
                pass
        except Exception as e:
            logger.debug(f"æ‰‹åŠ¨åˆ›å»ºç›®å½•å¤±è´¥ {member.name}: {e}")

    def _manual_create_symlink(self, member, rootfs_dir):
        """æ‰‹åŠ¨åˆ›å»ºç¬¦å·é“¾æ¥"""
        try:
            target_path = os.path.join(rootfs_dir, member.name)
            os.makedirs(os.path.dirname(target_path), exist_ok=True)

            # å¦‚æœç›®æ ‡å·²å­˜åœ¨ï¼Œå…ˆåˆ é™¤
            if os.path.exists(target_path) or os.path.islink(target_path):
                os.remove(target_path)

            os.symlink(member.linkname, target_path)
        except Exception as e:
            logger.debug(f"æ‰‹åŠ¨åˆ›å»ºç¬¦å·é“¾æ¥å¤±è´¥ {member.name}: {e}")

    def _is_android_environment(self):
        """æ£€æµ‹æ˜¯å¦åœ¨Androidç¯å¢ƒä¸­è¿è¡Œ"""
        android_indicators = [
            '/data/data/com.termux' in os.getcwd(),
            os.path.exists('/system/build.prop'),
            os.environ.get('ANDROID_DATA') is not None,
            os.environ.get('TERMUX_VERSION') is not None
        ]

        return any(android_indicators)

    def _extract_layer_with_tar(self, layer_path, rootfs_dir, is_first_layer=False):
        """ä½¿ç”¨tarå‘½ä»¤æå–å±‚ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        # æ£€æµ‹æ–‡ä»¶ç±»å‹å¹¶ä½¿ç”¨é€‚å½“çš„taré€‰é¡¹
        with open(layer_path, 'rb') as f:
            magic = f.read(2)

        # æ„å»ºåŸºç¡€å‘½ä»¤
        if magic == b'\x1f\x8b':  # gzip
            base_cmd = ['tar', '-xzf', layer_path, '-C', rootfs_dir]
        else:
            base_cmd = ['tar', '-xf', layer_path, '-C', rootfs_dir]

        # æ ¹æ®æ˜¯å¦ä¸ºç¬¬ä¸€å±‚å’Œç¯å¢ƒé€‰æ‹©ä¸åŒçš„é€‰é¡¹
        if self._is_android_environment():
            # åœ¨Androidç¯å¢ƒä¸­ï¼Œç›´æ¥ä½¿ç”¨æœ€å®½æ¾çš„æ¨¡å¼é¿å…ç¡¬é“¾æ¥é—®é¢˜
            tar_options = [
                '--no-same-owner',
                '--no-same-permissions',
                '--dereference'  # å°†ç¡¬é“¾æ¥è½¬æ¢ä¸ºæ™®é€šæ–‡ä»¶
            ]
            if not is_first_layer:
                tar_options.append('--overwrite')  # åç»­å±‚å…è®¸è¦†ç›–
        else:
            # æ ‡å‡†Linuxç¯å¢ƒé€‰é¡¹
            tar_options = [
                '--no-same-owner',
                '--no-same-permissions'
            ]

        cmd = base_cmd + tar_options

        # åœ¨Androidç¯å¢ƒä¸­ï¼Œç‰¹åˆ«æ˜¯ç¬¬ä¸€å±‚ï¼Œç›´æ¥ä½¿ç”¨å®½æ¾æ¨¡å¼é¿å…ç¡¬é“¾æ¥é—®é¢˜
        if self._is_android_environment() and is_first_layer:
            logger.info("ğŸ”§ æ£€æµ‹åˆ°Androidç¯å¢ƒç¬¬ä¸€å±‚ï¼Œä½¿ç”¨å®½æ¾æ¨¡å¼é¿å…ç¡¬é“¾æ¥é—®é¢˜")
            # å¯¹äºAndroidç¯å¢ƒçš„ç¬¬ä¸€å±‚ï¼Œç›´æ¥ä½¿ç”¨æœ€å®½æ¾çš„æ¨¡å¼
            fallback_cmd = base_cmd + [
                '--dereference',
                '--no-same-owner',
                '--no-same-permissions',
                '--skip-old-files'  # è·³è¿‡æœ‰é—®é¢˜çš„æ–‡ä»¶
            ]
            
            # ç›´æ¥ä½¿ç”¨subprocess.runï¼Œå…è®¸éé›¶é€€å‡ºç 
            result = subprocess.run(fallback_cmd, capture_output=True, text=True)

            if result.returncode == 0:
                if not self.quiet:
                    logger.debug("taræå–æˆåŠŸ")
            elif result.returncode == 2:
                # taré€€å‡ºç 2é€šå¸¸è¡¨ç¤ºæœ‰è­¦å‘Šä½†éƒ¨åˆ†æˆåŠŸ
                if not self.quiet:
                    logger.debug("taræå–å®Œæˆï¼ˆæœ‰è­¦å‘Šï¼Œä½†å¤§éƒ¨åˆ†æ–‡ä»¶å·²æå–ï¼‰")
                if self.verbose and result.stderr:
                    # åªåœ¨verboseæ¨¡å¼ä¸‹æ˜¾ç¤ºé”™è¯¯è¯¦æƒ…
                    error_lines = result.stderr.strip().split('\n')[:3]
                    logger.debug(f"tarè­¦å‘Šï¼ˆä»…æ˜¾ç¤ºå‰3è¡Œï¼‰: {error_lines}")
            else:
                logger.error(f"taræå–å¤±è´¥ï¼Œé€€å‡ºç : {result.returncode}")
                if result.stderr:
                    logger.error(f"é”™è¯¯ä¿¡æ¯: {result.stderr[:300]}...")  # é™åˆ¶é”™è¯¯ä¿¡æ¯é•¿åº¦
                raise subprocess.CalledProcessError(result.returncode, fallback_cmd, result.stderr)
        else:
            # å…¶ä»–æƒ…å†µä½¿ç”¨æ­£å¸¸æ¨¡å¼å’Œfallbackæœºåˆ¶
            logger.info(f"ğŸ“¦ ä½¿ç”¨æ ‡å‡†æ¨¡å¼æå– (Android: {self._is_android_environment()}, ç¬¬ä¸€å±‚: {is_first_layer})")
            try:
                self._run_command(cmd)
                logger.debug("taræå–æˆåŠŸ")
            except subprocess.CalledProcessError as e:
                # åªåœ¨équietæ¨¡å¼ä¸‹æ˜¾ç¤ºè­¦å‘Š
                if not getattr(self, 'quiet', False):
                    if not self.verbose:
                        logger.warning(f"tarå‘½ä»¤å¤±è´¥ï¼Œå°è¯•å®½æ¾æ¨¡å¼")
                    else:
                        logger.warning(f"tarå‘½ä»¤å¤±è´¥ï¼Œå°è¯•å®½æ¾æ¨¡å¼: {e}")

                # ä½¿ç”¨æœ€å®½æ¾çš„é€‰é¡¹ï¼Œå…è®¸é”™è¯¯ä½†ç»§ç»­
                fallback_cmd = base_cmd + [
                    '--dereference',
                    '--no-same-owner',
                    '--no-same-permissions',
                    '--skip-old-files'  # è·³è¿‡å·²å­˜åœ¨çš„æ–‡ä»¶
                ]

                # ç›´æ¥ä½¿ç”¨subprocess.runï¼Œå…è®¸éé›¶é€€å‡ºç 
                result = subprocess.run(fallback_cmd, capture_output=True, text=True)

                if result.returncode == 0:
                    if not self.quiet:
                        logger.info("ä½¿ç”¨å®½æ¾æ¨¡å¼æå–æˆåŠŸ")
                elif result.returncode == 2:
                    # taré€€å‡ºç 2é€šå¸¸è¡¨ç¤ºæœ‰è­¦å‘Šä½†éƒ¨åˆ†æˆåŠŸ
                    if not self.quiet:
                        logger.info("taræå–å®Œæˆï¼ˆæœ‰è­¦å‘Šï¼Œä½†å¤§éƒ¨åˆ†æ–‡ä»¶å·²æå–ï¼‰")
                    if self.verbose and result.stderr:
                        # åªåœ¨verboseæ¨¡å¼ä¸‹æ˜¾ç¤ºé”™è¯¯è¯¦æƒ…
                        error_lines = result.stderr.strip().split('\n')[:3]
                        logger.debug(f"tarè­¦å‘Šï¼ˆä»…æ˜¾ç¤ºå‰3è¡Œï¼‰: {error_lines}")
                else:
                    logger.error(f"taræå–å¤±è´¥ï¼Œé€€å‡ºç : {result.returncode}")
                    if result.stderr:
                        logger.error(f"é”™è¯¯ä¿¡æ¯: {result.stderr[:300]}...")  # é™åˆ¶é”™è¯¯ä¿¡æ¯é•¿åº¦
                    raise subprocess.CalledProcessError(result.returncode, fallback_cmd, result.stderr)


    
    def _create_tar_archive(self, rootfs_dir):
        """åˆ›å»ºtarå½’æ¡£æ–‡ä»¶"""
        output_path = os.path.abspath(self.output_path)
        
        # ä½¿ç”¨tarå‘½ä»¤åˆ›å»ºå½’æ¡£ï¼Œä¿æŒæƒé™å’Œæ‰€æœ‰è€…ä¿¡æ¯
        cmd = [
            'tar', 
            '-czf', output_path,
            '-C', rootfs_dir,
            '.'
        ]
        
        self._run_command(cmd)
        logger.info(f"æ ¹æ–‡ä»¶ç³»ç»ŸtaråŒ…å·²åˆ›å»º: {output_path}")
        return output_path
    
    def _optimize_for_proot(self, rootfs_dir):
        """ä¸ºprootä¼˜åŒ–æ ¹æ–‡ä»¶ç³»ç»Ÿ"""
        logger.info("ä¸ºprootä¼˜åŒ–æ ¹æ–‡ä»¶ç³»ç»Ÿ...")

        # åˆ›å»ºå¿…è¦çš„ç›®å½•
        essential_dirs = [
            'proc', 'sys', 'dev', 'tmp', 'run',
            'var/tmp', 'var/log', 'var/run'
        ]

        for dir_path in essential_dirs:
            full_path = os.path.join(rootfs_dir, dir_path)
            try:
                os.makedirs(full_path, exist_ok=True)
                logger.debug(f"ç¡®ä¿ç›®å½•å­˜åœ¨: {dir_path}")
            except OSError as e:
                # å¦‚æœç›®å½•å·²å­˜åœ¨ä½†æ˜¯æ–‡ä»¶ï¼Œå°è¯•åˆ é™¤åé‡å»º
                if os.path.exists(full_path) and not os.path.isdir(full_path):
                    try:
                        os.remove(full_path)
                        os.makedirs(full_path, exist_ok=True)
                        logger.debug(f"æ›¿æ¢æ–‡ä»¶ä¸ºç›®å½•: {dir_path}")
                    except OSError as e2:
                        logger.warning(f"æ— æ³•åˆ›å»ºç›®å½• {dir_path}: {e2}")
                else:
                    logger.debug(f"ç›®å½•å·²å­˜åœ¨: {dir_path}")
        
        # åˆ›å»ºåŸºæœ¬çš„è®¾å¤‡æ–‡ä»¶ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        dev_dir = os.path.join(rootfs_dir, 'dev')
        if os.path.exists(dev_dir):
            essential_devs = [
                ('null', 'c', 1, 3),
                ('zero', 'c', 1, 5),
                ('random', 'c', 1, 8),
                ('urandom', 'c', 1, 9)
            ]

            for dev_name, dev_type, major, minor in essential_devs:
                dev_path = os.path.join(dev_dir, dev_name)
                if not os.path.exists(dev_path):
                    try:
                        # æ³¨æ„ï¼šåœ¨æŸäº›ç¯å¢ƒä¸­å¯èƒ½æ²¡æœ‰æƒé™åˆ›å»ºè®¾å¤‡æ–‡ä»¶
                        # è¿™é‡Œåªæ˜¯å°è¯•ï¼Œå¤±è´¥äº†ä¹Ÿä¸å½±å“ä¸»è¦åŠŸèƒ½
                        if dev_type == 'c' and hasattr(os, 'mknod'):
                            os.mknod(dev_path, 0o666 | os.stat.S_IFCHR,
                                    os.makedev(major, minor))
                            logger.debug(f"åˆ›å»ºå­—ç¬¦è®¾å¤‡: {dev_name}")
                        else:
                            # å¦‚æœæ— æ³•åˆ›å»ºè®¾å¤‡æ–‡ä»¶ï¼Œåˆ›å»ºæ™®é€šæ–‡ä»¶ä½œä¸ºå ä½ç¬¦
                            with open(dev_path, 'w') as f:
                                f.write('')
                            logger.debug(f"åˆ›å»ºè®¾å¤‡æ–‡ä»¶å ä½ç¬¦: {dev_name}")
                    except (OSError, AttributeError) as e:
                        logger.debug(f"æ— æ³•åˆ›å»ºè®¾å¤‡æ–‡ä»¶ {dev_name}: {e} (è¿™é€šå¸¸æ˜¯æ­£å¸¸çš„)")
    
    def create_rootfs_tar(self):
        """ä¸»è¦çš„å¤„ç†æµç¨‹"""
        try:
            # æ£€æŸ¥ä¾èµ–
            if not self._check_dependencies():
                return False
            
            # åˆ›å»ºä¸´æ—¶ç›®å½•
            self._create_temp_directory()
            
            # ä½¿ç”¨Pythonä¸‹è½½é•œåƒ
            logger.info("æ­¥éª¤ 1/4: ä½¿ç”¨Pythonä¸‹è½½Dockeré•œåƒ...")
            oci_dir = self._download_image_with_python()
            
            # ä½¿ç”¨Pythonæå–æ ¹æ–‡ä»¶ç³»ç»Ÿ
            logger.info("æ­¥éª¤ 2/4: ä½¿ç”¨Pythonæå–æ ¹æ–‡ä»¶ç³»ç»Ÿ...")
            rootfs_dir = self._extract_rootfs_with_python(oci_dir)
            
                # ä¿å­˜é•œåƒé…ç½®
            logger.info("æ­¥éª¤ 3/5: ä¿å­˜é•œåƒé…ç½®...")
            self._save_image_config(oci_dir, rootfs_dir)

            # ä¸ºprootä¼˜åŒ–
            logger.info("æ­¥éª¤ 4/5: ä¸ºprootä¼˜åŒ–æ ¹æ–‡ä»¶ç³»ç»Ÿ...")
            self._optimize_for_proot(rootfs_dir)

            # åˆ›å»ºtarå½’æ¡£
            logger.info("æ­¥éª¤ 5/5: åˆ›å»ºtarå½’æ¡£...")
            output_file = self._create_tar_archive(rootfs_dir)
            
            logger.info(f"âœ“ æˆåŠŸåˆ›å»ºæ ¹æ–‡ä»¶ç³»ç»ŸtaråŒ…: {output_file}")
            logger.info(f"æ–‡ä»¶å¤§å°: {os.path.getsize(output_file) / 1024 / 1024:.2f} MB")
            
            # æä¾›ä½¿ç”¨è¯´æ˜
            self._print_usage_instructions(output_file)
            
            return True
            
        except Exception as e:
            logger.error(f"å¤„ç†å¤±è´¥: {str(e)}")
            return False
        finally:
            # æ¸…ç†ä¸´æ—¶ç›®å½•
            self._cleanup_temp_directory()
    
    def _print_usage_instructions(self, tar_file):
        """æ‰“å°ä½¿ç”¨è¯´æ˜"""
        logger.info("\n" + "="*50)
        logger.info("åœ¨Android Termuxä¸­ä½¿ç”¨prootçš„è¯´æ˜:")
        logger.info("="*50)
        logger.info("1. å°†taræ–‡ä»¶ä¼ è¾“åˆ°Androidè®¾å¤‡")
        logger.info("2. åœ¨Termuxä¸­å®‰è£…proot:")
        logger.info("   pkg install proot")
        logger.info("3. è§£å‹æ ¹æ–‡ä»¶ç³»ç»Ÿ:")
        logger.info(f"   mkdir rootfs && tar -xzf {os.path.basename(tar_file)} -C rootfs")
        logger.info("4. ä½¿ç”¨prootè¿›å…¥å®¹å™¨:")
        logger.info("   proot -r rootfs -b /dev -b /proc -b /sys /bin/sh")
        logger.info("æˆ–è€…ä½¿ç”¨æ›´å®Œæ•´çš„ç»‘å®š:")
        logger.info("   proot -r rootfs -b /dev -b /proc -b /sys -b /sdcard -w / /bin/sh")
        logger.info("="*50)
        logger.info("æ³¨æ„: æ­¤è„šæœ¬ä»…éœ€è¦curlå’Œtarå‘½ä»¤è¡Œå·¥å…·ï¼Œæ— éœ€skopeoã€umociå’Œrequestsåº“")
        logger.info("ä½¿ç”¨Pythonæ ‡å‡†åº“å®ç°é•œåƒè§£åŒ…ï¼Œé€‚åˆåœ¨å„ç§ç¯å¢ƒä¸­è¿è¡Œ")

def main():
    parser = argparse.ArgumentParser(
        description='ä½¿ç”¨curlå’ŒPythonåˆ¶ä½œDockeré•œåƒçš„æ ¹æ–‡ä»¶ç³»ç»ŸtaråŒ…'
    )
    parser.add_argument(
        'image_url',
        nargs='?',
        default='swr.cn-north-4.myhuaweicloud.com/ddn-k8s/docker.io/jeessy/ddns-go:v6.9.1-linuxarm64',
        help='Dockeré•œåƒURL (é»˜è®¤: ddns-goé•œåƒ)'
    )
    parser.add_argument(
        '-o', '--output',
        help='è¾“å‡ºtaræ–‡ä»¶è·¯å¾„ (é»˜è®¤: åŸºäºé•œåƒåç§°è‡ªåŠ¨ç”Ÿæˆ)'
    )
    parser.add_argument(
        '-v', '--verbose',
        action='store_true',
        help='æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—'
    )
    parser.add_argument(
        '--username',
        help='Docker Registryç”¨æˆ·å'
    )
    parser.add_argument(
        '--password',
        help='Docker Registryå¯†ç æˆ–token'
    )
    parser.add_argument(
        '--proxy',
        help='æŒ‡å®šç”¨äºcurlçš„ç½‘ç»œä»£ç† (ä¾‹å¦‚: "http://user:pass@host:port" æˆ– "socks5://host:port")'
    )
    
    parser.add_argument(
        '--arch',
        help='æŒ‡å®šç›®æ ‡æ¶æ„ (ä¾‹å¦‚: amd64, arm64)ã€‚é»˜è®¤ä¸ºè‡ªåŠ¨æ£€æµ‹ã€‚'
    )
    
    # æ–°å¢ç®€æ´æ¨¡å¼é€‰é¡¹
    parser.add_argument(
        '--quiet', '-q',
        action='store_true',
        help='ç®€æ´æ¨¡å¼ï¼šå‡å°‘å†—ä½™è¾“å‡ºï¼Œæ˜¾ç¤ºä¸‹è½½è¿›åº¦'
    )
    
    args = parser.parse_args()
    
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    # å¦‚æœä½¿ç”¨ç®€æ´æ¨¡å¼ï¼Œè®¾ç½®æ—¥å¿—çº§åˆ«ä¸ºERRORä»¥å‡å°‘ä¿¡æ¯è¾“å‡º
    if args.quiet:
        logging.getLogger().setLevel(logging.ERROR)
    
    logger.info(f"å¼€å§‹å¤„ç†Dockeré•œåƒ: {args.image_url}")
    logger.info("ğŸš€ [ç‰ˆæœ¬æ ‡è¯†] create_rootfs_tar.py v2.0 - å·²ä¼˜åŒ–ç¡¬é“¾æ¥å¤„ç†")
    
    # å°†ä»£ç†å‚æ•°ä¼ é€’ç»™å¤„ç†å™¨
    processor = DockerImageToRootFS(args.image_url, args.output, args.username, args.password, args.arch, args.verbose, args.quiet)
    # åœ¨å®¢æˆ·ç«¯ä¸­ä¹Ÿéœ€è¦è®¾ç½®ä»£ç†
    if args.proxy:
        # è¿™æ˜¯ä¸ªç®€åŒ–å¤„ç†ï¼Œç†æƒ³æƒ…å†µä¸‹åº”è¯¥åœ¨DockerRegistryClientä¸­å¤„ç†
        # ä½†ä¸ºäº†å¿«é€Ÿè§£å†³é—®é¢˜ï¼Œæˆ‘ä»¬é€šè¿‡ç¯å¢ƒå˜é‡è®¾ç½®
        os.environ['https_proxy'] = args.proxy
        os.environ['http_proxy'] = args.proxy
        logger.info(f"å·²è®¾ç½®ç½‘ç»œä»£ç†: {args.proxy}")
    success = processor.create_rootfs_tar()
    
    sys.exit(0 if success else 1)

if __name__ == '__main__':
    main()
