#!/usr/bin/env python3
"""
Dockeré£æ ¼çš„å‘½ä»¤è¡Œæ¥å£
æ¨¡ä»¿Dockerå‘½ä»¤è¡Œå·¥å…·ï¼Œæä¾›pullã€runã€psã€imagesç­‰å‘½ä»¤
ç”¨äºç®¡ç†é€šè¿‡prootè¿è¡Œçš„å®¹å™¨
"""

import os
import sys
import argparse
import json
import logging
import time
import subprocess
import signal
from pathlib import Path
from datetime import datetime
import getpass
from urllib.parse import urlparse

# å¯¼å…¥ç°æœ‰æ¨¡å—
from .proot_runner import ProotRunner
from .create_rootfs_tar import DockerImageToRootFS

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class DockerCLI:
    """Dockeré£æ ¼çš„å‘½ä»¤è¡Œæ¥å£"""
    
    def __init__(self, cache_dir=None):
        self.cache_dir = cache_dir or self._get_default_cache_dir()
        self.runner = ProotRunner(cache_dir=self.cache_dir)
        self.containers_file = os.path.join(self.cache_dir, 'containers.json')
        self.config_file = self._get_config_file_path()
        self._ensure_cache_dir()
        
    def _get_default_cache_dir(self):
        """è·å–é»˜è®¤ç¼“å­˜ç›®å½•"""
        home_dir = os.path.expanduser('~')
        return os.path.join(home_dir, '.docker_proot_cache')

    def _get_config_file_path(self):
        """è·å–é…ç½®æ–‡ä»¶çš„è·¯å¾„"""
        return os.path.join(self.cache_dir, 'config.json')

    def _ensure_cache_dir(self):
        """ç¡®ä¿ç¼“å­˜ç›®å½•å­˜åœ¨"""
        os.makedirs(self.cache_dir, exist_ok=True)
        
    def _load_containers(self):
        """åŠ è½½å®¹å™¨ä¿¡æ¯"""
        if os.path.exists(self.containers_file):
            try:
                with open(self.containers_file, 'r') as f:
                    return json.load(f)
            except Exception as e:
                logger.warning(f"è¯»å–å®¹å™¨ä¿¡æ¯å¤±è´¥: {e}")
        return {}
        
    def _save_containers(self, containers):
        """ä¿å­˜å®¹å™¨ä¿¡æ¯"""
        try:
            with open(self.containers_file, 'w') as f:
                json.dump(containers, f, indent=2)
        except Exception as e:
            logger.error(f"ä¿å­˜å®¹å™¨ä¿¡æ¯å¤±è´¥: {e}")

    def _load_config(self):
        """åŠ è½½é…ç½®ä¿¡æ¯ï¼ŒåŒ…æ‹¬è®¤è¯å‡­è¯"""
        if os.path.exists(self.config_file):
            try:
                with open(self.config_file, 'r') as f:
                    return json.load(f)
            except Exception as e:
                logger.warning(f"è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        return {'auths': {}}

    def _save_config(self, config):
        """ä¿å­˜é…ç½®ä¿¡æ¯"""
        try:
            with open(self.config_file, 'w') as f:
                json.dump(config, f, indent=2)
        except Exception as e:
            logger.error(f"ä¿å­˜é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
            
    def _generate_container_id(self):
        """ç”Ÿæˆå®¹å™¨ID"""
        import hashlib
        import uuid
        return hashlib.sha256(str(uuid.uuid4()).encode()).hexdigest()[:12]
    def _is_process_running(self, pid):
        """æ£€æŸ¥è¿›ç¨‹æ˜¯å¦è¿˜åœ¨è¿è¡Œ"""
        try:
            os.kill(pid, 0)
            return True
        except (OSError, ProcessLookupError):
            return False

    def _get_container_dir(self, container_id):
        """è·å–å®¹å™¨çš„æŒä¹…åŒ–æ•°æ®ç›®å½•"""
        return os.path.join(self.cache_dir, 'containers', container_id)

    def _get_pid_file(self, container_dir):
        """è·å–PIDæ–‡ä»¶è·¯å¾„"""
        return os.path.join(container_dir, 'container.pid')

    def _get_log_file(self, container_dir):
        """è·å–æ—¥å¿—æ–‡ä»¶è·¯å¾„"""
        return os.path.join(container_dir, 'container.log')

            
    def login(self, server, username, password):
        """ç™»å½•åˆ°Docker Registry"""
        if not username:
            username = input("Username: ")
        if not password:
            password = getpass.getpass("Password: ")

        config = self._load_config()
        if 'auths' not in config:
            config['auths'] = {}
        
        # é»˜è®¤æœåŠ¡å™¨ä¸ºDocker Hub
        if not server:
            server = "https://index.docker.io/v1/"

        config['auths'][server] = {
            'username': username,
            'password': password # For simplicity, storing plain text.
        }
        self._save_config(config)
        logger.info(f"ç™»å½•æˆåŠŸ: {server}")
        return True

    def pull(self, image_url, force=False, quiet=False):
        """æ‹‰å–é•œåƒ"""
        if not quiet:
            logger.info(f"æ‹‰å–é•œåƒ: {image_url}")

        # æ£€æŸ¥æ˜¯å¦å·²ç¼“å­˜
        if not force and self.runner._is_image_cached(image_url):
            cache_info = self.runner._load_cache_info(image_url)
            if cache_info:
                if not quiet:
                    logger.info(f"é•œåƒå·²å­˜åœ¨äºç¼“å­˜ä¸­")
                    logger.info(f"ç¼“å­˜æ—¶é—´: {cache_info.get('created_time_str', 'Unknown')}")
                else:
                    # åœ¨quietæ¨¡å¼ä¸‹ï¼Œåªè¾“å‡ºé•œåƒIDæˆ–åç§°
                    print(image_url)
                return True

        # åŠ è½½å‡­è¯
        config = self._load_config()
        auths = config.get('auths', {})
        
        # ç®€å•çš„åŒ¹é…é€»è¾‘ï¼Œå®é™…å¯èƒ½éœ€è¦æ›´å¤æ‚çš„åŒ¹é…
        # è¿™é‡Œæˆ‘ä»¬å‡è®¾é•œåƒURLçš„åŸŸåéƒ¨åˆ†èƒ½åŒ¹é…åˆ°authsä¸­çš„key
        username, password = None, None
        for server, creds in auths.items():
            server_name = urlparse(server).hostname or server
            if server_name in image_url or (server_name == "index.docker.io" and '/' not in image_url.split(':')[0]):
                username = creds.get('username')
                password = creds.get('password')
                logger.info(f"æ‰¾åˆ° {server} çš„å‡­è¯")
                break
        
        # ç°åœ¨pullç›´æ¥è°ƒç”¨runnerçš„ä¸‹è½½æ–¹æ³•
        if quiet:
            # åœ¨quietæ¨¡å¼ä¸‹ï¼Œä¸´æ—¶æŠ‘åˆ¶æ—¥å¿—è¾“å‡º
            original_level = logging.getLogger().level
            logging.getLogger().setLevel(logging.ERROR)
            
        try:
            cache_path = self.runner._download_image(
                image_url,
                force_download=force,
                username=username,
                password=password,
                quiet=quiet
            )
        finally:
            if quiet:
                # æ¢å¤åŸå§‹æ—¥å¿—çº§åˆ«
                logging.getLogger().setLevel(original_level)

        if cache_path:
            if not quiet:
                logger.info(f"âœ“ é•œåƒæ‹‰å–æˆåŠŸ: {image_url}")
            else:
                # åœ¨quietæ¨¡å¼ä¸‹ï¼Œåªè¾“å‡ºé•œåƒIDæˆ–åç§°
                print(image_url)
            return True
        else:
            if not quiet:
                logger.error(f"âœ— é•œåƒæ‹‰å–å¤±è´¥: {image_url}")
            return False
            
    def run(self, image_url, command=None, name=None, **kwargs):
        """è¿è¡Œå®¹å™¨"""
        # ç¡®ä¿åœ¨è¿è¡Œå‰é•œåƒå­˜åœ¨
        if not self.runner._is_image_cached(image_url) or kwargs.get('force_download', False):
            logger.info(f"é•œåƒä¸å­˜åœ¨æˆ–éœ€è¦å¼ºåˆ¶ä¸‹è½½ï¼Œæ‰§è¡Œ 'pull' æ“ä½œ...")
            pull_success = self.pull(image_url, force=kwargs.get('force_download', False), quiet=False)
            if not pull_success:
                logger.error(f"æ— æ³•è¿è¡Œå®¹å™¨ï¼Œå› ä¸ºé•œåƒæ‹‰å–å¤±è´¥: {image_url}")
                return None

        container_id = name if name else self._generate_container_id()
        container_dir = self._get_container_dir(container_id)
        os.makedirs(container_dir, exist_ok=True)
        
        # æ„å»ºè¿è¡Œå‚æ•°
        class Args:
            def __init__(self):
                self.env = kwargs.get('env', [])
                self.bind = kwargs.get('bind', [])
                for v in self.bind:
                    host_path = v.split(':')[0]
                    if not os.path.exists(host_path):
                        # ä»…è®°å½•è­¦å‘Šï¼Œè€Œä¸æ˜¯ä¸­æ­¢ï¼Œå› ä¸ºæŸäº›è·¯å¾„å¯èƒ½åœ¨å®¹å™¨å¯åŠ¨åæ‰å¯ç”¨
                        logger.warning(f"å·æŒ‚è½½çš„æºè·¯å¾„ä¸å­˜åœ¨: {host_path}")
                self.workdir = kwargs.get('workdir')
                self.detach = kwargs.get('detach', False)
                self.interactive = kwargs.get('interactive', False)
                self.force_download = kwargs.get('force_download', False)
                self.username = kwargs.get('username')
                self.password = kwargs.get('password')
                self.command = command
                if self.command and self.command[0] == '--':
                    self.command = self.command[1:]
                
        args = Args()
        
        # è®°å½•å®¹å™¨ä¿¡æ¯
        containers = self._load_containers()
        container_info = {
            'id': container_id,
            'image': image_url,
            'name': name,
            'command': command or [],
            'created': time.time(),
            'created_str': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'status': 'created',
            'pid': None,
            'container_dir': container_dir, 
            'detached': args.detach,
            'run_args': { # Store all arguments needed to restart
                'env': args.env,
                'bind': args.bind,
                'workdir': args.workdir,
            }
        }
        
        containers[container_id] = container_info
        self._save_containers(containers)

        logger.info(f"å¯åŠ¨å®¹å™¨: {container_id}")
        
        try:
            # Run container
            if args.detach:
                success = self._run_detached(image_url, args, container_id, container_dir)
            else:
                # For foreground mode, ProotRunner handles the temporary rootfs.
                container_info['status'] = 'running'
                containers[container_id] = container_info
                self._save_containers(containers)
                
                # We pass None for rootfs_dir so ProotRunner creates a temporary one
                success = self.runner.run(image_url, args, rootfs_dir=None)
                
                # Update status after completion
                container_info['status'] = 'exited'
                container_info['finished'] = time.time()
                container_info['finished_str'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                containers[container_id] = container_info
                # In foreground mode, the temporary rootfs is cleaned up by ProotRunner,
                # so we can remove the persistent container dir.
                if os.path.exists(container_dir):
                    import shutil
                    shutil.rmtree(container_dir)
                del containers[container_id]
                self._save_containers(containers)
                
            if success:
                if args.detach:
                    logger.info(f"å®¹å™¨ {container_id} å·²åœ¨åå°å¯åŠ¨")
                else:
                    logger.info(f"å®¹å™¨ {container_id} è¿è¡Œå®Œæˆ")
                return container_id
            else:
                container_info['status'] = 'failed'
                containers[container_id] = container_info
                self._save_containers(containers)
                return None
                
        except KeyboardInterrupt:
            container_info['status'] = 'interrupted'
            containers[container_id] = container_info
            self._save_containers(containers)
            logger.info(f"å®¹å™¨ {container_id} è¢«ç”¨æˆ·ä¸­æ–­")
            return container_id
            
    def _run_detached(self, image_url, args, container_id, container_dir):
        """åå°è¿è¡Œå®¹å™¨, ç›´æ¥è°ƒç”¨proot_runner.pyè„šæœ¬"""
        rootfs_dir = os.path.join(container_dir, 'rootfs')
        pid_file = self._get_pid_file(container_dir)
        log_file = self._get_log_file(container_dir)

        # æ„å»ºproot_runner.pyçš„å‘½ä»¤è¡Œå‚æ•°
        cmd = [
            sys.executable,
            '-m', 'android_docker.proot_runner',
            '--rootfs-dir', rootfs_dir,
            '--pid-file', pid_file,
            '--log-file', log_file,
            '--detach',
        ]
        
        # ç»Ÿä¸€ä»argså¯¹è±¡è·å–å‡­è¯
        if hasattr(args, 'username') and args.username:
            cmd.extend(['--username', args.username])
        if hasattr(args, 'password') and args.password:
            cmd.extend(['--password', args.password])

        # æ·»åŠ ä»docker_cliä¼ é€’è¿‡æ¥çš„å‚æ•°
        if args.force_download:
            cmd.append('--force-download')
        if args.workdir:
            cmd.extend(['--workdir', args.workdir])
        if args.interactive:
            cmd.append('--interactive')
        for e in args.env:
            cmd.extend(['-e', e])
        for b in args.bind:
            cmd.extend(['-b', b])
        
        # æ·»åŠ é•œåƒURLå’Œå‘½ä»¤
        # æ·»åŠ  -- åˆ†éš”ç¬¦æ¥åŒºåˆ† proot_runner.py çš„å‚æ•°å’Œå®¹å™¨çš„å‘½ä»¤
        cmd.append(image_url)
        if args.command:
            cmd.append('--')
            cmd.extend(args.command)

        try:
            logger.debug(f"Executing detached command: {' '.join(cmd)}")
            # æ‰“å¼€æ—¥å¿—æ–‡ä»¶ç”¨äºé‡å®šå‘è¾“å‡º
            with open(log_file, 'a') as lf:
                lf.write(f"--- Starting container at {datetime.now()} ---\\n")
                process = subprocess.Popen(
                    cmd,
                    stdout=lf,
                    stderr=lf,
                    stdin=subprocess.DEVNULL,
                    start_new_session=True
                )
            
            # ç­‰å¾…pidæ–‡ä»¶è¢«åˆ›å»ºï¼Œæœ€å¤šç­‰å¾…5ç§’
            pid = None
            # å»¶é•¿ç­‰å¾…æ—¶é—´è‡³15ç§’ (30 * 0.5s)
            for i in range(30):
                time.sleep(0.5)
                if os.path.exists(pid_file):
                    with open(pid_file, 'r') as pf:
                        pid_str = pf.read().strip()
                        if pid_str:
                            try:
                                pid = int(pid_str)
                                logger.debug(f"æˆåŠŸä»PIDæ–‡ä»¶è·å–PID: {pid}")
                                break
                            except ValueError:
                                logger.debug(f"PIDæ–‡ä»¶å†…å®¹æ— æ•ˆ: '{pid_str}'ï¼Œç»§ç»­ç­‰å¾…...")
                logger.debug(f"ç­‰å¾…PIDæ–‡ä»¶... (å°è¯• {i+1}/30)")
            
            if not pid:
                logger.error("æ— æ³•è·å–åå°è¿›ç¨‹çš„PIDï¼Œå¯åŠ¨å¯èƒ½å¤±è´¥ã€‚")
                logger.error(f"è¯·æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶è·å–æ›´å¤šä¿¡æ¯: {log_file}")
                return False

            # æ›´æ–°å®¹å™¨ä¿¡æ¯
            containers = self._load_containers()
            containers[container_id]['status'] = 'running'
            containers[container_id]['pid'] = pid
            self._save_containers(containers)
            
            return True
            
        except Exception as e:
            logger.error(f"å¯åŠ¨åå°å®¹å™¨å¤±è´¥: {e}")
            logger.error(f"è¯·æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶è·å–æ›´å¤šä¿¡æ¯: {log_file}")
            return False

            
    def _cleanup_stale_lock_files(self, rootfs_dir):
        """åœ¨é‡å¯å‰æ¸…ç†å¸¸è§çš„é™ˆæ—§é”æ–‡ä»¶æˆ–PIDæ–‡ä»¶"""
        logger.debug(f"æ­£åœ¨æ¸…ç†æ ¹æ–‡ä»¶ç³»ç»Ÿä¸­çš„é™ˆæ—§é”æ–‡ä»¶: {rootfs_dir}")
        lock_dirs = ['run', 'var/run', 'tmp']
        cleaned_files = 0

        for l_dir in lock_dirs:
            full_dir_path = os.path.join(rootfs_dir, l_dir.lstrip('/'))
            if os.path.isdir(full_dir_path):
                try:
                    for filename in os.listdir(full_dir_path):
                        if filename.endswith('.pid'):
                            file_path = os.path.join(full_dir_path, filename)
                            try:
                                os.remove(file_path)
                                logger.debug(f"å·²åˆ é™¤é™ˆæ—§çš„PIDæ–‡ä»¶: {file_path}")
                                cleaned_files += 1
                            except OSError as e:
                                logger.warning(f"åˆ é™¤PIDæ–‡ä»¶å¤±è´¥ {file_path}: {e}")
                except Exception as e:
                    logger.warning(f"æ‰«æç›®å½•å¤±è´¥ {full_dir_path}: {e}")
        
        if cleaned_files > 0:
            logger.info(f"æ¸…ç†äº† {cleaned_files} ä¸ªé™ˆæ—§çš„PID/é”æ–‡ä»¶ã€‚")
        else:
            logger.debug("æœªæ‰¾åˆ°éœ€è¦æ¸…ç†çš„é™ˆæ—§PID/é”æ–‡ä»¶ã€‚")

    def start(self, container_id):
        """å¯åŠ¨ä¸€ä¸ªå·²åœæ­¢çš„å®¹å™¨ï¼Œå¹¶ä¿æŒå…¶IDå’Œæ•°æ®ä¸å˜"""
        containers = self._load_containers()
        if container_id not in containers:
            logger.error(f"å®¹å™¨ä¸å­˜åœ¨: {container_id}")
            return False

        container_info = containers[container_id]
        status = container_info.get('status')

        if status == 'running':
            logger.error(f"å®¹å™¨ {container_id} å·²ç»åœ¨è¿è¡Œ")
            return False

        if status not in ['created', 'exited', 'killed', 'interrupted', 'failed']:
            logger.error(f"æ— æ³•å¯åŠ¨å¤„äº '{status}' çŠ¶æ€çš„å®¹å™¨ {container_id}")
            return False

        logger.info(f"æ­£åœ¨å¯åŠ¨å®¹å™¨: {container_id}")

        image_url = container_info['image']
        command = container_info['command']
        run_args = container_info.get('run_args', {})
        is_detached = container_info.get('detached', False)
        container_dir = container_info.get('container_dir')

        if not container_dir or not os.path.exists(container_dir):
            logger.error(f"æ‰¾ä¸åˆ°å®¹å™¨ {container_id} çš„æ•°æ®ç›®å½•ã€‚")
            return False

        rootfs_dir = os.path.join(container_dir, 'rootfs')
        if not os.path.exists(rootfs_dir):
            logger.error(f"æ‰¾ä¸åˆ°å®¹å™¨ {container_id} çš„æ ¹æ–‡ä»¶ç³»ç»Ÿã€‚")
            return False

        # æ¸…ç†æ—§çš„é”æ–‡ä»¶ï¼Œè¿™æ˜¯å…³é”®ä¿®å¤
        self._cleanup_stale_lock_files(rootfs_dir)

        class Args:
            def __init__(self):
                self.env = run_args.get('env', [])
                self.bind = run_args.get('bind', [])
                self.workdir = run_args.get('workdir')
                self.command = command
                self.detach = is_detached
                self.interactive = run_args.get('interactive', False)
                self.force_download = False

        args = Args()

        if is_detached:
            # For detached containers, we can reuse the _run_detached logic
            # It will handle logging, PID files, and command construction correctly.
            # We must first update the container status to 'restarting' or similar
            # because _run_detached assumes it's creating a new container.
            # However, a simpler fix is to call it and then update the container info.
            # The _run_detached method already saves container status.
            logger.info(f"Calling _run_detached to restart container {container_id}")
            success = self._run_detached(image_url, args, container_id, container_dir)
            
            if success:
                logger.info(f"å®¹å™¨ {container_id} å·²æˆåŠŸå¯åŠ¨")
            else:
                logger.error(f"å¯åŠ¨å®¹å™¨ {container_id} å¤±è´¥")

            return success
        else:
            # Foreground restart logic remains the same
            container_info['status'] = 'running'
            containers[container_id] = container_info
            self._save_containers(containers)
            success = self.runner.run(image_url, args, rootfs_dir=rootfs_dir)
            
            containers = self._load_containers()
            container_info = containers.get(container_id, {})
            container_info['status'] = 'exited'
            container_info['finished'] = time.time()
            container_info['finished_str'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            containers[container_id] = container_info
            self._save_containers(containers)
            return success

    def restart(self, container_id):
        """é‡å¯ä¸€ä¸ªå®¹å™¨"""
        logger.info(f"æ­£åœ¨é‡å¯å®¹å™¨: {container_id}")

        # 1. åœæ­¢å®¹å™¨ (å¦‚æœæ­£åœ¨è¿è¡Œ)
        containers = self._load_containers()
        if container_id not in containers:
            logger.error(f"å®¹å™¨ä¸å­˜åœ¨: {container_id}")
            return False

        status = containers[container_id].get('status')
        if status == 'running':
            stop_success = self.stop(container_id)
            if not stop_success:
                logger.error(f"æ— æ³•åœæ­¢å®¹å™¨ {container_id}ï¼Œé‡å¯å¤±è´¥")
                return False

        # 2. å¯åŠ¨å®¹å™¨
        start_success = self.start(container_id)
        if start_success:
            logger.info(f"æˆåŠŸé‡å¯å®¹å™¨ {container_id}")
        else:
            logger.error(f"é‡å¯å®¹å™¨ {container_id} å¤±è´¥")

        return start_success

    def logs(self, container_id, follow=False):
        """æ˜¾ç¤ºå®¹å™¨çš„æ—¥å¿—"""
        containers = self._load_containers()
        if container_id not in containers:
            logger.error(f"å®¹å™¨ä¸å­˜åœ¨: {container_id}")
            return False

        container_info = containers[container_id]
        container_dir = container_info.get('container_dir')
        if not container_dir:
            logger.error(f"æ‰¾ä¸åˆ°å®¹å™¨ {container_id} çš„æ—¥å¿—æ–‡ä»¶è·¯å¾„")
            return False
            
        log_file = self._get_log_file(container_dir)
        if not os.path.exists(log_file):
            logger.info(f"å®¹å™¨ {container_id} æ²¡æœ‰æ—¥å¿—")
            return True

        try:
            with open(log_file, 'r') as f:
                if not follow:
                    # Print existing content and exit
                    print(f.read(), end='')
                    return True
                else:
                    # Follow mode (like tail -f)
                    # Print existing content first
                    print(f.read(), end='')
                    # Then wait for new content
                    while True:
                        line = f.readline()
                        if not line:
                            time.sleep(0.1)
                            continue
                        print(line, end='')
        except KeyboardInterrupt:
            print() # Print a newline after Ctrl+C
            return True
        except Exception as e:
            logger.error(f"è¯»å–æ—¥å¿—å¤±è´¥: {e}")
            return False

    def attach(self, container_id):
        """é€šè¿‡åœ¨å®¹å™¨ä¸­æ‰§è¡Œä¸€ä¸ªäº¤äº’å¼shellæ¥é™„åŠ åˆ°å®¹å™¨"""
        logger.info(f"é™„åŠ åˆ°å®¹å™¨ {container_id} (é€šè¿‡ 'exec -it <shell>' å®ç°)")
        logger.info("è¾“å…¥ 'exit' æˆ–æŒ‰ Ctrl+D é€€å‡º.")
        # Attach is implemented by executing an interactive shell in the container.
        return self.exec(container_id, [], interactive=True)

    def exec(self, container_id, command, interactive=False):
        """åœ¨è¿è¡Œä¸­çš„å®¹å™¨ä¸­æ‰§è¡Œå‘½ä»¤"""
        containers = self._load_containers()
        if container_id not in containers:
            logger.error(f"å®¹å™¨ä¸å­˜åœ¨: {container_id}")
            return False

        container_info = containers[container_id]
        status = container_info.get('status')
        if status != 'running':
            logger.error(f"å®¹å™¨ {container_id} æœªåœ¨è¿è¡Œä¸­")
            return False

        pid = container_info.get('pid')
        if not pid:
            logger.error(f"å®¹å™¨ {container_id} æ²¡æœ‰PIDä¿¡æ¯")
            return False

        if not self._is_process_running(pid):
            logger.error(f"å®¹å™¨ {container_id} è¿›ç¨‹æœªè¿è¡Œ")
            return False

        # Get container directory and rootfs path
        container_dir = container_info.get('container_dir')
        if not container_dir:
            logger.error(f"æ‰¾ä¸åˆ°å®¹å™¨ {container_id} çš„ç›®å½•")
            return False

        rootfs_dir = os.path.join(container_dir, 'rootfs')
        if not os.path.exists(rootfs_dir):
            logger.error(f"æ‰¾ä¸åˆ°å®¹å™¨ {container_id} çš„æ ¹æ–‡ä»¶ç³»ç»Ÿ")
            return False

        # Build exec command using proot
        proot_cmd = ['proot', '-r', rootfs_dir]
        
        # Add default binds
        default_binds = ['/dev', '/proc', '/sys']
        for bind in default_binds:
            if os.path.exists(bind):
                proot_cmd.extend(['-b', bind])

        # Add user specified binds from original container
        original_binds = container_info.get('run_args', {}).get('bind', [])
        for bind in original_binds:
            proot_cmd.extend(['-b', bind])

        # Set working directory
        workdir = container_info.get('run_args', {}).get('workdir') or '/'
        proot_cmd.extend(['-w', workdir])

        # If no command provided, use default shell
        if not command:
            # Find available shell
            default_shells = ['/bin/bash', '/bin/sh']
            shell = '/bin/sh'  # default fallback
            for s in default_shells:
                shell_path = os.path.join(rootfs_dir, s.lstrip('/'))
                if os.path.exists(shell_path):
                    shell = s
                    break
            command = [shell]
        elif isinstance(command, str):
            # If command is a string, convert it to a list
            command = [command]
        
        # Ensure command is a list and not None
        if not isinstance(command, list):
            command = [str(command)] if command else ['/bin/sh']

        # Add the command to execute
        proot_cmd.extend(command)

        logger.info(f"åœ¨å®¹å™¨ {container_id} ä¸­æ‰§è¡Œå‘½ä»¤: {' '.join(command)}")
        
        try:
            if interactive:
                # Interactive mode: connect stdin/stdout/stderr
                env = os.environ.copy()
                # Remove LD_PRELOAD for Android Termux compatibility
                if 'LD_PRELOAD' in env:
                    del env['LD_PRELOAD']
                subprocess.run(proot_cmd, env=env)
            else:
                # Non-interactive mode: capture output
                env = os.environ.copy()
                # Remove LD_PRELOAD for Android Termux compatibility
                if 'LD_PRELOAD' in env:
                    del env['LD_PRELOAD']
                result = subprocess.run(proot_cmd, env=env, capture_output=True, text=True)
                if result.stdout:
                    print(result.stdout, end='')
                if result.stderr:
                    print(result.stderr, end='', file=sys.stderr)
                return result.returncode == 0
            return True
        except Exception as e:
            logger.error(f"æ‰§è¡Œå‘½ä»¤å¤±è´¥: {e}")
            return False

    def ps(self, all_containers=False):
        """åˆ—å‡ºå®¹å™¨"""
        containers = self._load_containers()
        
        if not containers:
            logger.info("æ²¡æœ‰å®¹å™¨")
            return
            
        # æ›´æ–°è¿è¡Œä¸­å®¹å™¨çš„çŠ¶æ€
        for container_id, info in containers.items():
            if info.get('status') == 'running' and info.get('pid'):
                # å¯¹äºé€šè¿‡æ–°æ–¹æ³•å¯åŠ¨çš„å®¹å™¨ï¼Œpidæ˜¯prootè¿›ç¨‹çš„çœŸå®pid
                if not self._is_process_running(info['pid']):
                    info['status'] = 'exited'
                    info['finished'] = time.time()
                    info['finished_str'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            elif info.get('status') == 'running' and info.get('script_path'):
                 # å…¼å®¹æ—§çš„ã€é€šè¿‡wrapper scriptå¯åŠ¨çš„å®¹å™¨
                if not self._is_process_running(info['pid']):
                    info['status'] = 'exited'
                    info['finished'] = time.time()
                    info['finished_str'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

        
        self._save_containers(containers)
        
        # è¿‡æ»¤å®¹å™¨
        if not all_containers:
            containers = {k: v for k, v in containers.items() 
                         if v.get('status') in ['running', 'created']}
            
        if not containers:
            logger.info("æ²¡æœ‰è¿è¡Œä¸­çš„å®¹å™¨")
            return
            
        # æ˜¾ç¤ºå®¹å™¨åˆ—è¡¨
        print(f"{'CONTAINER ID':<12} {'IMAGE':<30} {'COMMAND':<20} {'CREATED':<20} {'STATUS':<10}")
        print("-" * 100)
        
        for container_id, info in containers.items():
            image = info.get('image', 'unknown')[:28]
            command = ' '.join(info.get('command', []))[:18] or 'default'
            created = info.get('created_str', 'unknown')
            status = info.get('status', 'unknown')
            
            print(f"{container_id:<12} {image:<30} {command:<20} {created:<20} {status:<10}")
            
    def images(self):
        """åˆ—å‡ºé•œåƒ"""
        logger.info("åˆ—å‡ºç¼“å­˜çš„é•œåƒ:")
        self.runner.list_cache()
        
    def rmi(self, image_url):
        """åˆ é™¤é•œåƒ"""
        logger.info(f"åˆ é™¤é•œåƒ: {image_url}")
        try:
            self.runner.clear_cache(image_url)
            return True
        except Exception as e:
            logger.error(f"åˆ é™¤é•œåƒå¤±è´¥: {e}")
            return False
        
    def stop(self, container_id):
        """åœæ­¢å®¹å™¨"""
        containers = self._load_containers()
        
        if container_id not in containers:
            logger.error(f"å®¹å™¨ä¸å­˜åœ¨: {container_id}")
            return False
            
        container_info = containers[container_id]
        pid = container_info.get('pid')
        
        if pid and not self._is_process_running(pid):
            logger.info(f"å®¹å™¨ {container_id} è¿›ç¨‹å·²åœæ­¢ï¼Œæ›´æ–°çŠ¶æ€ä¸º 'exited'")
            container_info['status'] = 'exited'
            container_info['finished'] = time.time()
            container_info['finished_str'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            self._save_containers(containers)
            return True

        # å¦‚æœæ²¡æœ‰PIDï¼Œæˆ–è€…PIDå¯¹åº”çš„è¿›ç¨‹æ²¡æœ‰è¿è¡Œï¼Œå¹¶ä¸”å®¹å™¨çŠ¶æ€ä¸æ˜¯è¿è¡Œä¸­ï¼Œåˆ™ç›´æ¥è®¤ä¸ºå·²åœæ­¢
        if not pid or not self._is_process_running(pid):
            if container_info.get('status') in ['exited', 'killed', 'failed', 'created']:
                logger.info(f"å®¹å™¨ {container_id} å·²ç»åœæ­¢æˆ–å¤„äºéè¿è¡ŒçŠ¶æ€ ({container_info.get('status')}).")
                # ç¡®ä¿çŠ¶æ€è¢«æ­£ç¡®æ›´æ–°ï¼Œå³ä½¿PIDç¼ºå¤±
                if container_info.get('status') != 'exited':
                    container_info['status'] = 'exited'
                    container_info['finished'] = time.time()
                    container_info['finished_str'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                    self._save_containers(containers)
                return True
            else:
                logger.warning(f"å®¹å™¨ {container_id} æ²¡æœ‰æœ‰æ•ˆçš„PIDä¿¡æ¯æˆ–è¿›ç¨‹æœªè¿è¡Œï¼Œä½†çŠ¶æ€ä¸º {container_info.get('status')}. å°è¯•å¼ºåˆ¶åœæ­¢.")
                # å¯¹äºé‚£äº›çŠ¶æ€å¼‚å¸¸ï¼ˆå¦‚'running'ä½†æ— PIDæˆ–è¿›ç¨‹ï¼‰ï¼Œå°è¯•å¼ºåˆ¶æ¸…ç†
                # è¿™éƒ¨åˆ†é€»è¾‘éœ€è¦éå¸¸å°å¿ƒï¼Œä»¥é¿å…è¯¯åˆ æ•°æ®
                # å¯¹äºdocker-compose downåœºæ™¯ï¼Œå¦‚æœstopå¤±è´¥ï¼Œrmä¼šæ¥ç®¡æ¸…ç†å·¥ä½œ
                # æ‰€ä»¥è¿™é‡Œä¸»è¦ç›®çš„æ˜¯è®©stopè¿”å›Trueï¼Œè®©rmå¯ä»¥ç»§ç»­æ‰§è¡Œ
                container_info['status'] = 'exited' # å¼ºåˆ¶æ ‡è®°ä¸ºå·²é€€å‡ºï¼Œä»¥ä¾¿rmå¯ä»¥å¤„ç†
                container_info['finished'] = time.time()
                container_info['finished_str'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                self._save_containers(containers)
                return True
            
        try:
            # å‘é€SIGTERMä¿¡å·åˆ°æ•´ä¸ªè¿›ç¨‹ç»„
            os.killpg(pid, signal.SIGTERM)
            logger.info(f"å·²å‘é€åœæ­¢ä¿¡å·ç»™å®¹å™¨è¿›ç¨‹ç»„ {container_id} (PGID: {pid})")
            
            # ç­‰å¾…ä¸€æ®µæ—¶é—´åæ£€æŸ¥æ˜¯å¦åœæ­¢
            time.sleep(2)
            if not self._is_process_running(pid):
                container_info['status'] = 'exited'
                container_info['finished'] = time.time()
                container_info['finished_str'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                containers[container_id] = container_info
                self._save_containers(containers)
                logger.info(f"å®¹å™¨ {container_id} å·²åœæ­¢")
                return True
            else:
                logger.warning(f"å®¹å™¨ {container_id} æœªå“åº”SIGTERMï¼Œå°è¯•SIGKILL")
                os.killpg(pid, signal.SIGKILL)
                container_info['status'] = 'killed'
                containers[container_id] = container_info
                self._save_containers(containers)
                return True
                
        except (OSError, ProcessLookupError) as e:
            logger.error(f"åœæ­¢å®¹å™¨å¤±è´¥: {e}")
            return False
            
    def rm(self, container_id, force=False):
        """åˆ é™¤å®¹å™¨"""
        containers = self._load_containers()
        
        if container_id not in containers:
            logger.error(f"å®¹å™¨ä¸å­˜åœ¨: {container_id}")
            return False
            
        container_info = containers[container_id]
        
        # æ£€æŸ¥å®¹å™¨æ˜¯å¦åœ¨è¿è¡Œ
        # æ›´æ–°çŠ¶æ€ä»¥é˜²ä¸‡ä¸€
        if container_info.get('status') == 'running' and container_info.get('pid'):
            if not self._is_process_running(container_info['pid']):
                container_info['status'] = 'exited'
        
        if container_info.get('status') == 'running':
            if not force:
                logger.error(f"å®¹å™¨ {container_id} æ­£åœ¨è¿è¡Œï¼Œä½¿ç”¨ --force å¼ºåˆ¶åˆ é™¤")
                return False
            else:
                # å¼ºåˆ¶åœæ­¢å®¹å™¨
                logger.info(f"å¼ºåˆ¶åœæ­¢å®¹å™¨: {container_id}")
                self.stop(container_id)
                # é‡æ–°åŠ è½½ä¿¡æ¯
                containers = self._load_containers()
                container_info = containers.get(container_id, {})
                if not container_info:
                    logger.info(f"å®¹å™¨ {container_id} åœ¨åœæ­¢åå·²è¢«ç§»é™¤")
                    return True
                
        # æ¸…ç†å®¹å™¨çš„æŒä¹…åŒ–ç›®å½•
        container_dir = container_info.get('container_dir')
        if container_dir and os.path.isdir(container_dir):
            try:
                import shutil
                shutil.rmtree(container_dir)
                logger.debug(f"å·²æ¸…ç†å®¹å™¨ç›®å½•: {container_dir}")
            except OSError as e:
                logger.warning(f"æ¸…ç†å®¹å™¨ç›®å½•å¤±è´¥ {container_dir}: {e}")

        # å…¼å®¹æ—§çš„æ¸…ç†é€»è¾‘
        rootfs_dir = container_info.get('rootfs_dir')
        if rootfs_dir and os.path.isdir(rootfs_dir):
            try:
                import shutil
                shutil.rmtree(rootfs_dir)
            except OSError:
                pass

        script_path = container_info.get('script_path')
        if script_path and os.path.exists(script_path):
            try:
                os.remove(script_path)
            except OSError:
                pass
                
        # åˆ é™¤å®¹å™¨è®°å½•
        if container_id in containers:
            del containers[container_id]
            self._save_containers(containers)
        
        logger.info(f"å®¹å™¨ {container_id} å·²åˆ é™¤")
        return True

    def volume_rm(self, volume_name):
        """åˆ é™¤å·"""
        logger.info(f"åˆ é™¤å·: {volume_name}")
        try:
            # è¿™é‡Œå¯ä»¥å®ç°å·çš„åˆ é™¤é€»è¾‘
            # ä¾‹å¦‚ï¼Œå¦‚æœå·æ˜¯åŸºäºç›®å½•çš„ï¼Œåˆ™åˆ é™¤ç›®å½•
            # å¦‚æœå·æ˜¯åŸºäºæ–‡ä»¶çš„ï¼Œåˆ™åˆ é™¤æ–‡ä»¶
            # å¦‚æœå·æ˜¯åŸºäºå®¹å™¨çš„ï¼Œåˆ™éœ€è¦åœæ­¢å®¹å™¨æˆ–åˆ é™¤å®¹å™¨
            # ç”±äºprootçš„é™åˆ¶ï¼Œè¿™é‡Œä¸»è¦æ˜¯æ¦‚å¿µæ€§å®ç°
            logger.warning("å·åˆ é™¤åŠŸèƒ½åœ¨prootç¯å¢ƒä¸‹æœ‰é™åˆ¶ï¼Œå»ºè®®æ‰‹åŠ¨æ¸…ç†")
            return True
        except Exception as e:
            logger.error(f"åˆ é™¤å·å¤±è´¥: {e}")
            return False

    def build(self, dockerfile_path, tag=None, context_path="."):
        """æ„å»ºDockeré•œåƒ"""
        logger.info(f"æ„å»ºé•œåƒ: {dockerfile_path}")
        # è¿™é‡Œå¯ä»¥å®ç°ç®€å•çš„é•œåƒæ„å»ºé€»è¾‘
        # ç”±äºprootçš„é™åˆ¶ï¼Œè¿™é‡Œä¸»è¦æ˜¯æ¦‚å¿µæ€§å®ç°
        logger.warning("é•œåƒæ„å»ºåŠŸèƒ½åœ¨prootç¯å¢ƒä¸‹æœ‰é™åˆ¶ï¼Œå»ºè®®ä½¿ç”¨é¢„æ„å»ºçš„é•œåƒ")
        return True

    def save(self, image_url, output_path):
        """ä¿å­˜é•œåƒåˆ°taræ–‡ä»¶ï¼ˆDockerå¯¼å…¥æ ¼å¼ï¼‰"""
        logger.info(f"ä¿å­˜é•œåƒ {image_url} åˆ° {output_path}")
        try:
            # æ ‡å‡†åŒ–é•œåƒåç§°ï¼ˆæ·»åŠ é»˜è®¤tagï¼‰
            if ':' not in image_url:
                full_image_url = image_url + ':latest'
            else:
                full_image_url = image_url
            
            # æ£€æŸ¥é•œåƒæ˜¯å¦å­˜åœ¨ï¼ˆæ·»åŠ è°ƒè¯•ä¿¡æ¯ï¼‰
            logger.debug(f"æ£€æŸ¥é•œåƒ: {full_image_url}")
            logger.debug(f"å¤‡é€‰é•œåƒå: {image_url}")
            
            if not self.runner._is_image_cached(full_image_url):
                logger.debug(f"é•œåƒ {full_image_url} ä¸å­˜åœ¨ï¼Œå°è¯• {image_url}")
                # å¦‚æœå¸¦tagçš„ä¸å­˜åœ¨ï¼Œå°è¯•ä¸å¸¦tagçš„
                if not self.runner._is_image_cached(image_url):
                    logger.error(f"é•œåƒ {image_url} ä¸å­˜åœ¨")
                    # åˆ—å‡ºå¯ç”¨çš„é•œåƒè¿›è¡Œè°ƒè¯•
                    logger.info("å¯ç”¨çš„é•œåƒ:")
                    self.runner.list_cache()
                    return False
                else:
                    full_image_url = image_url
                    logger.debug(f"ä½¿ç”¨é•œåƒå: {full_image_url}")
            else:
                logger.debug(f"æ‰¾åˆ°é•œåƒ: {full_image_url}")
            
            # è·å–é•œåƒçš„ç¼“å­˜è·¯å¾„
            cache_path = self.runner._get_image_cache_path(full_image_url)
            
            if os.path.exists(cache_path):
                # ç›´æ¥å¤åˆ¶tar.gzæ–‡ä»¶ï¼ˆè¿™æ˜¯æ ¹æ–‡ä»¶ç³»ç»Ÿï¼Œå¯ç”¨äºdocker importï¼‰
                import shutil
                shutil.copy2(cache_path, output_path)
                
                logger.info(f"é•œåƒå·²ä¿å­˜åˆ° {output_path}")
                logger.info("æ³¨æ„ï¼šæ­¤æ–‡ä»¶æ˜¯æ ¹æ–‡ä»¶ç³»ç»Ÿæ ¼å¼ï¼ˆARM64æ¶æ„ï¼‰ï¼Œè¯·æ ¹æ®æ‚¨çš„å®¹å™¨å·¥å…·é€‰æ‹©å¯¼å…¥æ–¹å¼ï¼š")
                logger.info("")
                logger.info("ğŸ“¦ Docker ç¯å¢ƒ:")
                logger.info(f"  docker import --platform linux/arm64 {output_path} {image_url}:arm64")
                logger.info(f"  docker push {image_url}:arm64")
                logger.info("")
                logger.info("ğŸ¦­ Podman ç¯å¢ƒ:")
                logger.info("  # æ–¹æ³•1: ä½¿ç”¨ Dockerfile")
                logger.info(f"  echo 'FROM scratch' > Dockerfile.import")
                logger.info(f"  echo 'ADD {os.path.basename(output_path)} /' >> Dockerfile.import")
                logger.info(f"  echo 'CMD [\"/docker-entrypoint.sh\", \"nginx\", \"-g\", \"daemon off;\"]' >> Dockerfile.import")
                logger.info(f"  podman build --platform linux/arm64 -t {image_url}:arm64 -f Dockerfile.import .")
                logger.info("")
                logger.info("  # æ–¹æ³•2: ç›´æ¥å¯¼å…¥ï¼ˆæ¶æ„å¯èƒ½ä¸å‡†ç¡®ï¼‰")
                logger.info(f"  podman import {output_path} {image_url}:arm64")
                return True
            else:
                logger.error(f"é•œåƒæ–‡ä»¶ {cache_path} ä¸å­˜åœ¨")
                return False
        except Exception as e:
            logger.error(f"ä¿å­˜é•œåƒå¤±è´¥: {e}")
            return False

    def load(self, tar_path):
        """ä»taræ–‡ä»¶åŠ è½½é•œåƒ"""
        logger.info(f"ä» {tar_path} åŠ è½½é•œåƒ")
        try:
            import tarfile
            with tarfile.open(tar_path, 'r') as tar:
                # æå–åˆ°ä¸´æ—¶ç›®å½•
                temp_dir = os.path.join(self.cache_dir, 'temp_load')
                os.makedirs(temp_dir, exist_ok=True)
                tar.extractall(temp_dir)
                
                # è¿™é‡Œå¯ä»¥æ·»åŠ é•œåƒå¯¼å…¥é€»è¾‘
                logger.info("é•œåƒåŠ è½½å®Œæˆ")
                return True
        except Exception as e:
            logger.error(f"åŠ è½½é•œåƒå¤±è´¥: {e}")
            return False

    def tag(self, source_image, target_image):
        """ä¸ºé•œåƒæ·»åŠ æ ‡ç­¾"""
        logger.info(f"ä¸ºé•œåƒ {source_image} æ·»åŠ æ ‡ç­¾ {target_image}")
        try:
            # æ£€æŸ¥æºé•œåƒæ˜¯å¦å­˜åœ¨ï¼ˆä½¿ç”¨runnerçš„ç¼“å­˜è·¯å¾„ï¼‰
            if not self.runner._is_image_cached(source_image):
                logger.error(f"æºé•œåƒ {source_image} ä¸å­˜åœ¨")
                return False
            
            # è·å–æºé•œåƒçš„ç¼“å­˜è·¯å¾„
            source_cache_path = self.runner._get_image_cache_path(source_image)
            target_cache_path = self.runner._get_image_cache_path(target_image)
            
            if os.path.exists(source_cache_path):
                # å¤åˆ¶tar.gzæ–‡ä»¶
                import shutil
                shutil.copy2(source_cache_path, target_cache_path)
                
                # å¤åˆ¶infoæ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                source_info_path = source_cache_path + '.info'
                target_info_path = target_cache_path + '.info'
                if os.path.exists(source_info_path):
                    shutil.copy2(source_info_path, target_info_path)
                
                # ä¿å­˜æ–°çš„ç¼“å­˜ä¿¡æ¯
                self.runner._save_cache_info(target_image, target_cache_path)
                
                logger.info(f"æ ‡ç­¾æ·»åŠ æˆåŠŸ: {target_image}")
                return True
            else:
                logger.error(f"æºé•œåƒæ–‡ä»¶ {source_cache_path} ä¸å­˜åœ¨")
                return False
        except Exception as e:
            logger.error(f"æ·»åŠ æ ‡ç­¾å¤±è´¥: {e}")
            return False

    def inspect(self, target):
        """æ£€æŸ¥å®¹å™¨æˆ–é•œåƒçš„è¯¦ç»†ä¿¡æ¯"""
        logger.info(f"æ£€æŸ¥ {target} çš„è¯¦ç»†ä¿¡æ¯")
        try:
            # æ£€æŸ¥æ˜¯å¦æ˜¯å®¹å™¨
            containers = self._load_containers()
            if target in containers:
                container_info = containers[target]
                print(json.dumps(container_info, indent=2, ensure_ascii=False))
                return True
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯é•œåƒ
            image_dir = os.path.join(self.cache_dir, 'images', target.replace(':', '_'))
            if os.path.exists(image_dir):
                image_info = {
                    'Id': target,
                    'RepoTags': [target],
                    'Created': datetime.fromtimestamp(os.path.getctime(image_dir)).isoformat(),
                    'Size': self._get_dir_size(image_dir),
                    'Architecture': 'unknown',
                    'Os': 'linux'
                }
                print(json.dumps(image_info, indent=2, ensure_ascii=False))
                return True
            
            logger.error(f"æœªæ‰¾åˆ°å®¹å™¨æˆ–é•œåƒ: {target}")
            return False
        except Exception as e:
            logger.error(f"æ£€æŸ¥å¤±è´¥: {e}")
            return False

    def top(self, container_id):
        """æ˜¾ç¤ºå®¹å™¨ä¸­è¿è¡Œçš„è¿›ç¨‹"""
        logger.info(f"æ˜¾ç¤ºå®¹å™¨ {container_id} çš„è¿›ç¨‹")
        try:
            containers = self._load_containers()
            if container_id not in containers:
                logger.error(f"å®¹å™¨ {container_id} ä¸å­˜åœ¨")
                return False
            
            container = containers[container_id]
            pid = container.get('pid')
            if not pid or not self._is_process_running(pid):
                logger.error(f"å®¹å™¨ {container_id} æœªè¿è¡Œ")
                return False
            
            # ä½¿ç”¨pså‘½ä»¤æŸ¥çœ‹è¿›ç¨‹
            try:
                result = subprocess.run(['ps', '-p', str(pid), '-o', 'pid,ppid,cmd'], 
                                      capture_output=True, text=True)
                print(result.stdout)
                return True
            except Exception as e:
                logger.error(f"è·å–è¿›ç¨‹ä¿¡æ¯å¤±è´¥: {e}")
                return False
        except Exception as e:
            logger.error(f"topå‘½ä»¤å¤±è´¥: {e}")
            return False

    def stats(self, container_id=None):
        """æ˜¾ç¤ºå®¹å™¨çš„èµ„æºä½¿ç”¨ç»Ÿè®¡"""
        logger.info("æ˜¾ç¤ºå®¹å™¨èµ„æºç»Ÿè®¡")
        try:
            containers = self._load_containers()
            if container_id:
                if container_id not in containers:
                    logger.error(f"å®¹å™¨ {container_id} ä¸å­˜åœ¨")
                    return False
                container_list = [container_id]
            else:
                container_list = list(containers.keys())
            
            print(f"{'å®¹å™¨ID':<12} {'CPU%':<8} {'å†…å­˜ä½¿ç”¨':<12} {'å†…å­˜%':<8} {'ç½‘ç»œI/O':<20} {'ç£ç›˜I/O':<20}")
            print("-" * 80)
            
            for cid in container_list:
                container = containers[cid]
                pid = container.get('pid')
                if pid and self._is_process_running(pid):
                    # è¿™é‡Œå¯ä»¥æ·»åŠ å®é™…çš„èµ„æºç»Ÿè®¡é€»è¾‘
                    print(f"{cid:<12} {'0.0':<8} {'0 B':<12} {'0.0':<8} {'0 B / 0 B':<20} {'0 B / 0 B':<20}")
                else:
                    print(f"{cid:<12} {'--':<8} {'--':<12} {'--':<8} {'--':<20} {'--':<20}")
            
            return True
        except Exception as e:
            logger.error(f"statså‘½ä»¤å¤±è´¥: {e}")
            return False

    def cp(self, source, dest):
        """åœ¨å®¹å™¨å’Œä¸»æœºä¹‹é—´å¤åˆ¶æ–‡ä»¶"""
        logger.info(f"å¤åˆ¶æ–‡ä»¶: {source} -> {dest}")
        try:
            # è§£ææºå’Œç›®æ ‡è·¯å¾„
            if ':' in source:
                container_id, container_path = source.split(':', 1)
                is_copy_from_container = True
            elif ':' in dest:
                container_id, container_path = dest.split(':', 1)
                is_copy_from_container = False
            else:
                logger.error("å¤åˆ¶å‘½ä»¤æ ¼å¼é”™è¯¯ï¼Œåº”ä¸º: docker cp CONTAINER:CONTAINER_PATH HOST_PATH æˆ– docker cp HOST_PATH CONTAINER:CONTAINER_PATH")
                return False
            
            containers = self._load_containers()
            if container_id not in containers:
                logger.error(f"å®¹å™¨ {container_id} ä¸å­˜åœ¨")
                return False
            
            container = containers[container_id]
            container_rootfs = container.get('rootfs_dir')
            if not container_rootfs:
                logger.error(f"å®¹å™¨ {container_id} çš„rootfsç›®å½•ä¸å­˜åœ¨")
                return False
            
            if is_copy_from_container:
                # ä»å®¹å™¨å¤åˆ¶åˆ°ä¸»æœº
                source_path = os.path.join(container_rootfs, container_path)
                if os.path.exists(source_path):
                    import shutil
                    if os.path.isdir(source_path):
                        shutil.copytree(source_path, dest, dirs_exist_ok=True)
                    else:
                        shutil.copy2(source_path, dest)
                    logger.info(f"æ–‡ä»¶å·²ä»å®¹å™¨å¤åˆ¶åˆ°ä¸»æœº: {dest}")
                    return True
                else:
                    logger.error(f"å®¹å™¨å†…è·¯å¾„ä¸å­˜åœ¨: {container_path}")
                    return False
            else:
                # ä»ä¸»æœºå¤åˆ¶åˆ°å®¹å™¨
                dest_path = os.path.join(container_rootfs, container_path)
                if os.path.exists(source):
                    import shutil
                    os.makedirs(os.path.dirname(dest_path), exist_ok=True)
                    if os.path.isdir(source):
                        shutil.copytree(source, dest_path, dirs_exist_ok=True)
                    else:
                        shutil.copy2(source, dest_path)
                    logger.info(f"æ–‡ä»¶å·²ä»ä¸»æœºå¤åˆ¶åˆ°å®¹å™¨: {dest_path}")
                    return True
                else:
                    logger.error(f"ä¸»æœºè·¯å¾„ä¸å­˜åœ¨: {source}")
                    return False
        except Exception as e:
            logger.error(f"å¤åˆ¶æ–‡ä»¶å¤±è´¥: {e}")
            return False

    def diff(self, container_id):
        """æ˜¾ç¤ºå®¹å™¨æ–‡ä»¶ç³»ç»Ÿçš„å˜æ›´"""
        logger.info(f"æ˜¾ç¤ºå®¹å™¨ {container_id} çš„æ–‡ä»¶ç³»ç»Ÿå˜æ›´")
        try:
            containers = self._load_containers()
            if container_id not in containers:
                logger.error(f"å®¹å™¨ {container_id} ä¸å­˜åœ¨")
                return False
            
            container = containers[container_id]
            container_rootfs = container.get('rootfs_dir')
            if not container_rootfs:
                logger.error(f"å®¹å™¨ {container_id} çš„rootfsç›®å½•ä¸å­˜åœ¨")
                return False
            
            # è¿™é‡Œå¯ä»¥å®ç°æ–‡ä»¶ç³»ç»Ÿå˜æ›´æ£€æµ‹é€»è¾‘
            # ç”±äºprootçš„é™åˆ¶ï¼Œè¿™é‡Œä¸»è¦æ˜¯æ¦‚å¿µæ€§å®ç°
            logger.info("æ–‡ä»¶ç³»ç»Ÿå˜æ›´æ£€æµ‹åŠŸèƒ½åœ¨prootç¯å¢ƒä¸‹æœ‰é™åˆ¶")
            return True
        except Exception as e:
            logger.error(f"diffå‘½ä»¤å¤±è´¥: {e}")
            return False

    def commit(self, container_id, repository, tag="latest"):
        """ä»å®¹å™¨åˆ›å»ºæ–°é•œåƒ"""
        logger.info(f"ä»å®¹å™¨ {container_id} åˆ›å»ºé•œåƒ {repository}:{tag}")
        try:
            containers = self._load_containers()
            if container_id not in containers:
                logger.error(f"å®¹å™¨ {container_id} ä¸å­˜åœ¨")
                return False
            
            container = containers[container_id]
            container_rootfs = container.get('rootfs_dir')
            if not container_rootfs:
                logger.error(f"å®¹å™¨ {container_id} çš„rootfsç›®å½•ä¸å­˜åœ¨")
                return False
            
            # åˆ›å»ºæ–°é•œåƒç›®å½•
            image_name = f"{repository}:{tag}"
            image_dir = os.path.join(self.cache_dir, 'images', image_name.replace(':', '_'))
            
            if os.path.exists(image_dir):
                import shutil
                shutil.rmtree(image_dir)
            
            import shutil
            shutil.copytree(container_rootfs, image_dir)
            
            logger.info(f"é•œåƒåˆ›å»ºæˆåŠŸ: {image_name}")
            return True
        except Exception as e:
            logger.error(f"åˆ›å»ºé•œåƒå¤±è´¥: {e}")
            return False

    def export(self, container_id, output_path):
        """å¯¼å‡ºå®¹å™¨æ–‡ä»¶ç³»ç»Ÿåˆ°taræ–‡ä»¶"""
        logger.info(f"å¯¼å‡ºå®¹å™¨ {container_id} åˆ° {output_path}")
        try:
            containers = self._load_containers()
            if container_id not in containers:
                logger.error(f"å®¹å™¨ {container_id} ä¸å­˜åœ¨")
                return False
            
            container = containers[container_id]
            container_rootfs = container.get('rootfs_dir')
            if not container_rootfs:
                logger.error(f"å®¹å™¨ {container_id} çš„rootfsç›®å½•ä¸å­˜åœ¨")
                return False
            
            import tarfile
            with tarfile.open(output_path, 'w') as tar:
                tar.add(container_rootfs, arcname='.')
            
            logger.info(f"å®¹å™¨å·²å¯¼å‡ºåˆ° {output_path}")
            return True
        except Exception as e:
            logger.error(f"å¯¼å‡ºå®¹å™¨å¤±è´¥: {e}")
            return False

    def import_(self, tar_path, repository, tag="latest"):
        """ä»taræ–‡ä»¶å¯¼å…¥é•œåƒ"""
        logger.info(f"ä» {tar_path} å¯¼å…¥é•œåƒ {repository}:{tag}")
        try:
            import tarfile
            image_name = f"{repository}:{tag}"
            image_dir = os.path.join(self.cache_dir, 'images', image_name.replace(':', '_'))
            
            if os.path.exists(image_dir):
                import shutil
                shutil.rmtree(image_dir)
            
            os.makedirs(image_dir, exist_ok=True)
            
            with tarfile.open(tar_path, 'r') as tar:
                tar.extractall(image_dir)
            
            logger.info(f"é•œåƒå¯¼å…¥æˆåŠŸ: {image_name}")
            return True
        except Exception as e:
            logger.error(f"å¯¼å…¥é•œåƒå¤±è´¥: {e}")
            return False

    def history(self, image_url):
        """æ˜¾ç¤ºé•œåƒçš„å†å²è®°å½•"""
        logger.info(f"æ˜¾ç¤ºé•œåƒ {image_url} çš„å†å²è®°å½•")
        try:
            image_dir = os.path.join(self.cache_dir, 'images', image_url.replace(':', '_'))
            if not os.path.exists(image_dir):
                logger.error(f"é•œåƒ {image_url} ä¸å­˜åœ¨")
                return False
            
            # ç”±äºprootçš„é™åˆ¶ï¼Œè¿™é‡Œä¸»è¦æ˜¯æ¦‚å¿µæ€§å®ç°
            print(f"IMAGE          CREATED       CREATED BY                                      SIZE      COMMENT")
            print(f"{image_url:<15} {datetime.fromtimestamp(os.path.getctime(image_dir)):<13} /bin/sh -c #(nop) ADD file:...   0 B")
            logger.info("å†å²è®°å½•åŠŸèƒ½åœ¨prootç¯å¢ƒä¸‹æœ‰é™åˆ¶")
            return True
        except Exception as e:
            logger.error(f"historyå‘½ä»¤å¤±è´¥: {e}")
            return False

    def info(self):
        """æ˜¾ç¤ºç³»ç»Ÿä¿¡æ¯"""
        logger.info("æ˜¾ç¤ºç³»ç»Ÿä¿¡æ¯")
        try:
            import platform
            import psutil
            
            info = {
                'Containers': len(self._load_containers()),
                'Images': len([d for d in os.listdir(os.path.join(self.cache_dir, 'images')) if os.path.isdir(os.path.join(self.cache_dir, 'images', d))]),
                'System Time': datetime.now().isoformat(),
                'Operating System': platform.system(),
                'Architecture': platform.machine(),
                'Kernel Version': platform.release(),
                'Total Memory': f"{psutil.virtual_memory().total / (1024**3):.2f} GB",
                'Available Memory': f"{psutil.virtual_memory().available / (1024**3):.2f} GB",
                'Cache Directory': self.cache_dir
            }
            
            for key, value in info.items():
                print(f"{key}: {value}")
            
            return True
        except Exception as e:
            logger.error(f"infoå‘½ä»¤å¤±è´¥: {e}")
            return False

    def version(self):
        """æ˜¾ç¤ºç‰ˆæœ¬ä¿¡æ¯"""
        logger.info("æ˜¾ç¤ºç‰ˆæœ¬ä¿¡æ¯")
        try:
            import platform
            version_info = {
                'Version': '1.0.0',
                'API Version': '1.41',
                'Go Version': 'N/A',
                'Git Commit': 'N/A',
                'Built': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'OS/Arch': f"{platform.system()}/{platform.machine()}",
                'Experimental': 'false'
            }
            
            for key, value in version_info.items():
                print(f"{key}: {value}")
            
            return True
        except Exception as e:
            logger.error(f"versionå‘½ä»¤å¤±è´¥: {e}")
            return False

    def help(self, command=None):
        """æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯"""
        if command:
            logger.info(f"æ˜¾ç¤ºå‘½ä»¤ {command} çš„å¸®åŠ©ä¿¡æ¯")
            # è¿™é‡Œå¯ä»¥æ˜¾ç¤ºç‰¹å®šå‘½ä»¤çš„å¸®åŠ©
            print(f"docker {command} å‘½ä»¤çš„å¸®åŠ©ä¿¡æ¯")
        else:
            logger.info("æ˜¾ç¤ºDockerå¸®åŠ©ä¿¡æ¯")
            print("Dockerå‘½ä»¤å¸®åŠ©:")
            print("  run        è¿è¡Œå®¹å™¨")
            print("  start      å¯åŠ¨å®¹å™¨")
            print("  stop       åœæ­¢å®¹å™¨")
            print("  restart    é‡å¯å®¹å™¨")
            print("  ps         åˆ—å‡ºå®¹å™¨")
            print("  logs       æŸ¥çœ‹å®¹å™¨æ—¥å¿—")
            print("  attach     é™„åŠ åˆ°å®¹å™¨")
            print("  exec       åœ¨å®¹å™¨ä¸­æ‰§è¡Œå‘½ä»¤")
            print("  rm         åˆ é™¤å®¹å™¨")
            print("  pull       æ‹‰å–é•œåƒ")
            print("  images     åˆ—å‡ºé•œåƒ")
            print("  rmi        åˆ é™¤é•œåƒ")
            print("  login      ç™»å½•åˆ°Registry")
            print("  build      æ„å»ºé•œåƒ")
            print("  save       ä¿å­˜é•œåƒ")
            print("  load       åŠ è½½é•œåƒ")
            print("  tag        ä¸ºé•œåƒæ·»åŠ æ ‡ç­¾")
            print("  inspect    æ£€æŸ¥å®¹å™¨æˆ–é•œåƒ")
            print("  top        æ˜¾ç¤ºå®¹å™¨è¿›ç¨‹")
            print("  stats      æ˜¾ç¤ºå®¹å™¨ç»Ÿè®¡")
            print("  cp         å¤åˆ¶æ–‡ä»¶")
            print("  diff       æ˜¾ç¤ºæ–‡ä»¶ç³»ç»Ÿå˜æ›´")
            print("  commit     ä»å®¹å™¨åˆ›å»ºé•œåƒ")
            print("  export     å¯¼å‡ºå®¹å™¨")
            print("  import     å¯¼å…¥é•œåƒ")
            print("  history    æ˜¾ç¤ºé•œåƒå†å²")
            print("  info       æ˜¾ç¤ºç³»ç»Ÿä¿¡æ¯")
            print("  version    æ˜¾ç¤ºç‰ˆæœ¬ä¿¡æ¯")
            print("  help       æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯")
            print("  network    ç½‘ç»œç®¡ç†")
            print("  volume     å·ç®¡ç†")
            print("  system     ç³»ç»Ÿç®¡ç†")
        return True

    def _get_dir_size(self, path):
        """è·å–ç›®å½•å¤§å°"""
        total_size = 0
        try:
            for dirpath, dirnames, filenames in os.walk(path):
                for filename in filenames:
                    filepath = os.path.join(dirpath, filename)
                    if os.path.exists(filepath):
                        total_size += os.path.getsize(filepath)
        except Exception:
            pass
        return total_size

    def network_create(self, name, driver="bridge"):
        """åˆ›å»ºç½‘ç»œ"""
        logger.info(f"åˆ›å»ºç½‘ç»œ: {name} (é©±åŠ¨: {driver})")
        try:
            networks_file = os.path.join(self.cache_dir, 'networks.json')
            networks = {}
            if os.path.exists(networks_file):
                with open(networks_file, 'r') as f:
                    networks = json.load(f)
            
            if name in networks:
                logger.error(f"ç½‘ç»œ {name} å·²å­˜åœ¨")
                return False
            
            network_id = self._generate_container_id()
            networks[name] = {
                'id': network_id,
                'name': name,
                'driver': driver,
                'created': datetime.now().isoformat(),
                'containers': []
            }
            
            with open(networks_file, 'w') as f:
                json.dump(networks, f, indent=2)
            
            logger.info(f"ç½‘ç»œ {name} åˆ›å»ºæˆåŠŸ")
            return True
        except Exception as e:
            logger.error(f"åˆ›å»ºç½‘ç»œå¤±è´¥: {e}")
            return False

    def network_ls(self):
        """åˆ—å‡ºç½‘ç»œ"""
        logger.info("åˆ—å‡ºç½‘ç»œ")
        try:
            networks_file = os.path.join(self.cache_dir, 'networks.json')
            if not os.path.exists(networks_file):
                print("æ²¡æœ‰æ‰¾åˆ°ç½‘ç»œ")
                return True
            
            with open(networks_file, 'r') as f:
                networks = json.load(f)
            
            print(f"{'ç½‘ç»œID':<12} {'åç§°':<20} {'é©±åŠ¨':<10} {'ä½œç”¨åŸŸ':<10}")
            print("-" * 60)
            
            for name, network in networks.items():
                print(f"{network['id']:<12} {name:<20} {network['driver']:<10} {'local':<10}")
            
            return True
        except Exception as e:
            logger.error(f"åˆ—å‡ºç½‘ç»œå¤±è´¥: {e}")
            return False

    def network_rm(self, name):
        """åˆ é™¤ç½‘ç»œ"""
        logger.info(f"åˆ é™¤ç½‘ç»œ: {name}")
        try:
            networks_file = os.path.join(self.cache_dir, 'networks.json')
            if not os.path.exists(networks_file):
                logger.error(f"ç½‘ç»œ {name} ä¸å­˜åœ¨")
                return False
            
            with open(networks_file, 'r') as f:
                networks = json.load(f)
            
            if name not in networks:
                logger.error(f"ç½‘ç»œ {name} ä¸å­˜åœ¨")
                return False
            
            # æ£€æŸ¥ç½‘ç»œæ˜¯å¦è¢«å®¹å™¨ä½¿ç”¨
            if networks[name]['containers']:
                logger.error(f"ç½‘ç»œ {name} æ­£åœ¨è¢«å®¹å™¨ä½¿ç”¨ï¼Œæ— æ³•åˆ é™¤")
                return False
            
            del networks[name]
            
            with open(networks_file, 'w') as f:
                json.dump(networks, f, indent=2)
            
            logger.info(f"ç½‘ç»œ {name} åˆ é™¤æˆåŠŸ")
            return True
        except Exception as e:
            logger.error(f"åˆ é™¤ç½‘ç»œå¤±è´¥: {e}")
            return False

    def volume_create(self, name):
        """åˆ›å»ºå·"""
        logger.info(f"åˆ›å»ºå·: {name}")
        try:
            volumes_file = os.path.join(self.cache_dir, 'volumes.json')
            volumes = {}
            if os.path.exists(volumes_file):
                with open(volumes_file, 'r') as f:
                    volumes = json.load(f)
            
            if name in volumes:
                logger.error(f"å· {name} å·²å­˜åœ¨")
                return False
            
            volume_id = self._generate_container_id()
            volume_path = os.path.join(self.cache_dir, 'volumes', name)
            os.makedirs(volume_path, exist_ok=True)
            
            volumes[name] = {
                'id': volume_id,
                'name': name,
                'path': volume_path,
                'created': datetime.now().isoformat(),
                'containers': []
            }
            
            with open(volumes_file, 'w') as f:
                json.dump(volumes, f, indent=2)
            
            logger.info(f"å· {name} åˆ›å»ºæˆåŠŸ")
            return True
        except Exception as e:
            logger.error(f"åˆ›å»ºå·å¤±è´¥: {e}")
            return False

    def volume_ls(self):
        """åˆ—å‡ºå·"""
        logger.info("åˆ—å‡ºå·")
        try:
            volumes_file = os.path.join(self.cache_dir, 'volumes.json')
            if not os.path.exists(volumes_file):
                print("æ²¡æœ‰æ‰¾åˆ°å·")
                return True
            
            with open(volumes_file, 'r') as f:
                volumes = json.load(f)
            
            print(f"{'å·å':<20} {'é©±åŠ¨':<10} {'æŒ‚è½½ç‚¹':<50}")
            print("-" * 80)
            
            for name, volume in volumes.items():
                print(f"{name:<20} {'local':<10} {volume['path']:<50}")
            
            return True
        except Exception as e:
            logger.error(f"åˆ—å‡ºå·å¤±è´¥: {e}")
            return False

    def volume_rm(self, name):
        """åˆ é™¤å·"""
        logger.info(f"åˆ é™¤å·: {name}")
        try:
            volumes_file = os.path.join(self.cache_dir, 'volumes.json')
            if not os.path.exists(volumes_file):
                logger.error(f"å· {name} ä¸å­˜åœ¨")
                return False
            
            with open(volumes_file, 'r') as f:
                volumes = json.load(f)
            
            if name not in volumes:
                logger.error(f"å· {name} ä¸å­˜åœ¨")
                return False
            
            # æ£€æŸ¥å·æ˜¯å¦è¢«å®¹å™¨ä½¿ç”¨
            if volumes[name]['containers']:
                logger.error(f"å· {name} æ­£åœ¨è¢«å®¹å™¨ä½¿ç”¨ï¼Œæ— æ³•åˆ é™¤")
                return False
            
            # åˆ é™¤å·ç›®å½•
            volume_path = volumes[name]['path']
            if os.path.exists(volume_path):
                import shutil
                shutil.rmtree(volume_path)
            
            del volumes[name]
            
            with open(volumes_file, 'w') as f:
                json.dump(volumes, f, indent=2)
            
            logger.info(f"å· {name} åˆ é™¤æˆåŠŸ")
            return True
        except Exception as e:
            logger.error(f"åˆ é™¤å·å¤±è´¥: {e}")
            return False

    def system_prune(self, all_resources=False):
        """æ¸…ç†æœªä½¿ç”¨çš„èµ„æº"""
        logger.info("æ¸…ç†æœªä½¿ç”¨çš„èµ„æº")
        try:
            cleaned = 0
            
            # æ¸…ç†åœæ­¢çš„å®¹å™¨
            containers = self._load_containers()
            for container_id, container in list(containers.items()):
                if not self._is_process_running(container.get('pid', 0)):
                    logger.info(f"æ¸…ç†åœæ­¢çš„å®¹å™¨: {container_id}")
                    del containers[container_id]
                    cleaned += 1
            
            self._save_containers(containers)
            
            # æ¸…ç†æœªä½¿ç”¨çš„é•œåƒï¼ˆå¯é€‰ï¼‰
            if all_resources:
                logger.info("æ¸…ç†æœªä½¿ç”¨çš„é•œåƒ")
                # è¿™é‡Œå¯ä»¥æ·»åŠ é•œåƒæ¸…ç†é€»è¾‘
            
            logger.info(f"æ¸…ç†å®Œæˆï¼Œå…±æ¸…ç† {cleaned} ä¸ªèµ„æº")
            return True
        except Exception as e:
            logger.error(f"æ¸…ç†èµ„æºå¤±è´¥: {e}")
            return False

    def push(self, image_url, tag="latest"):
        """æ¨é€é•œåƒåˆ°Docker Registry
        
        æ³¨æ„ï¼šåœ¨prootç¯å¢ƒä¸‹ï¼Œæ­¤åŠŸèƒ½å—åˆ°é™åˆ¶ï¼Œä¸»è¦ç”¨äºæ¦‚å¿µæ€§æ¼”ç¤º
        """
        logger.info(f"æ¨é€é•œåƒ: {image_url}:{tag}")
        
        try:
            # æ£€æŸ¥é•œåƒæ˜¯å¦å­˜åœ¨ï¼ˆä½¿ç”¨runnerçš„ç¼“å­˜æ£€æŸ¥æ–¹æ³•ï¼‰
            if not self.runner._is_image_cached(image_url):
                logger.error(f"é•œåƒ {image_url} ä¸å­˜åœ¨ï¼Œè¯·å…ˆä½¿ç”¨ docker pull ä¸‹è½½")
                return False
            
            # è·å–é•œåƒçš„ç¼“å­˜è·¯å¾„
            cache_path = self.runner._get_image_cache_path(image_url)
            logger.info(f"æ‰¾åˆ°é•œåƒæ–‡ä»¶: {cache_path}")
            
            # æ£€æŸ¥è®¤è¯ä¿¡æ¯
            config = self._load_config()
            auths = config.get('auths', {})
            
            # ç¡®å®šregistryæœåŠ¡å™¨
            image_without_tag = image_url.split(':')[0]
            if '/' in image_without_tag and '.' in image_without_tag.split('/')[0]:
                # å¦‚æœç¬¬ä¸€éƒ¨åˆ†åŒ…å«ç‚¹ï¼Œè¯´æ˜æ˜¯è‡ªå®šä¹‰registryï¼ˆå¦‚ my-registry.com/imageï¼‰
                registry = image_without_tag.split('/')[0]
            else:
                # å¦åˆ™æ˜¯Docker Hubé•œåƒï¼ˆåŒ…æ‹¬ç”¨æˆ·é•œåƒå¦‚ xiaochen1649/nginxï¼‰
                registry = "index.docker.io"
            
            # æŸ¥æ‰¾å¯¹åº”çš„è®¤è¯ä¿¡æ¯
            logger.debug(f"æŸ¥æ‰¾registryè®¤è¯ä¿¡æ¯: {registry}")
            logger.debug(f"å¯ç”¨çš„è®¤è¯æœåŠ¡å™¨: {list(auths.keys())}")
            
            username = None
            password = None
            for server, creds in auths.items():
                server_name = urlparse(server).hostname or server
                logger.debug(f"æ£€æŸ¥æœåŠ¡å™¨: {server} (è§£æä¸º: {server_name})")
                if server_name == registry or (server_name == "index.docker.io" and registry == "index.docker.io"):
                    username = creds.get('username')
                    password = creds.get('password')
                    logger.debug(f"æ‰¾åˆ°åŒ¹é…çš„è®¤è¯ä¿¡æ¯")
                    break
            
            if not username or not password:
                logger.error(f"æœªæ‰¾åˆ° {registry} çš„è®¤è¯ä¿¡æ¯ï¼Œè¯·å…ˆä½¿ç”¨ docker login ç™»å½•")
                return False
            
            logger.info(f"ä½¿ç”¨è®¤è¯ä¿¡æ¯æ¨é€åˆ° {registry}")
            
            # åœ¨prootç¯å¢ƒä¸‹ï¼Œå®é™…çš„æ¨é€åŠŸèƒ½å—åˆ°é™åˆ¶
            # è¿™é‡Œä¸»è¦æä¾›æ¦‚å¿µæ€§æ¼”ç¤ºå’Œé”™è¯¯æ£€æŸ¥
            logger.warning("æ³¨æ„ï¼šåœ¨prootç¯å¢ƒä¸‹ï¼Œå®é™…çš„é•œåƒæ¨é€åŠŸèƒ½å—åˆ°é™åˆ¶")
            logger.info("æ­¤å‘½ä»¤ä¸»è¦ç”¨äºéªŒè¯é•œåƒå­˜åœ¨æ€§å’Œè®¤è¯ä¿¡æ¯")
            
            # æ¨¡æ‹Ÿæ¨é€è¿‡ç¨‹
            logger.info(f"é•œåƒ {image_url}:{tag} å·²å‡†å¤‡å¥½æ¨é€")
            logger.info("åœ¨æ ‡å‡†Dockerç¯å¢ƒä¸­ï¼Œé•œåƒå°†è¢«æ¨é€åˆ°è¿œç¨‹ä»“åº“")
            
            return True
            
        except Exception as e:
            logger.error(f"æ¨é€é•œåƒå¤±è´¥: {e}")
            return False

def create_parser():
    """åˆ›å»ºå‘½ä»¤è¡Œè§£æå™¨"""
    parser = argparse.ArgumentParser(
        prog='docker',
        description='Dockeré£æ ¼çš„prootå®¹å™¨ç®¡ç†å·¥å…·',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # æ‹‰å–é•œåƒ
  %(prog)s pull alpine:latest
  %(prog)s pull nginx:alpine

  # è¿è¡Œå®¹å™¨
  %(prog)s run alpine:latest
  %(prog)s run -d nginx:alpine
  %(prog)s run -it alpine:latest /bin/sh
  %(prog)s run -e "API_KEY=123" -v /host:/container alpine:latest /bin/sh

  # æŸ¥çœ‹å®¹å™¨
  %(prog)s ps
  %(prog)s ps -a

  # æŸ¥çœ‹é•œåƒ
  %(prog)s images

  # åœæ­¢å’Œåˆ é™¤å®¹å™¨
  %(prog)s stop <container_id>
  %(prog)s rm <container_id>

  # é™„åŠ åˆ°è¿è¡Œä¸­çš„å®¹å™¨
  %(prog)s attach <container_id>

  # åœ¨è¿è¡Œä¸­çš„å®¹å™¨ä¸­æ‰§è¡Œå‘½ä»¤
  %(prog)s exec <container_id> ls -l
  %(prog)s exec -it <container_id> /bin/sh

  # åˆ é™¤é•œåƒ
  %(prog)s rmi alpine:latest
        """
    )

    parser.add_argument(
        '--cache-dir',
        help='æŒ‡å®šç¼“å­˜ç›®å½•è·¯å¾„'
    )

    parser.add_argument(
        '--verbose',
        action='store_true',
        help='æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—'
    )

    subparsers = parser.add_subparsers(dest='subcommand', help='å¯ç”¨å‘½ä»¤', required=True)

    # login å‘½ä»¤
    login_parser = subparsers.add_parser('login', help='ç™»å½•åˆ°Docker Registry')
    login_parser.add_argument('server', nargs='?', default=None, help='RegistryæœåŠ¡å™¨åœ°å€ (é»˜è®¤ä¸ºDocker Hub)')
    login_parser.add_argument('-u', '--username', help='ç”¨æˆ·å')
    login_parser.add_argument('-p', '--password', help='å¯†ç ')

    # pull å‘½ä»¤
    pull_parser = subparsers.add_parser('pull', help='æ‹‰å–é•œåƒ')
    pull_parser.add_argument('image', help='é•œåƒURL')
    pull_parser.add_argument('--force', action='store_true', help='å¼ºåˆ¶é‡æ–°ä¸‹è½½')
    pull_parser.add_argument('-q', '--quiet', action='store_true', help='é™é»˜æ¨¡å¼ï¼Œä»…æ˜¾ç¤ºé•œåƒID')

    # push å‘½ä»¤
    push_parser = subparsers.add_parser('push', help='æ¨é€é•œåƒåˆ°Docker Registry')
    push_parser.add_argument('image', help='é•œåƒåç§°')
    push_parser.add_argument('-t', '--tag', default='latest', help='é•œåƒæ ‡ç­¾ (é»˜è®¤: latest)')

    # run å‘½ä»¤
    run_parser = subparsers.add_parser('run', help='è¿è¡Œå®¹å™¨')
    run_parser.add_argument('image', help='é•œåƒURL')
    run_parser.add_argument('--name', help='ä¸ºå®¹å™¨æŒ‡å®šä¸€ä¸ªåç§°')
    run_parser.add_argument('command', nargs='*', help='è¦æ‰§è¡Œçš„å‘½ä»¤')
    run_parser.add_argument('-d', '--detach', action='store_true', help='åå°è¿è¡Œ')
    run_parser.add_argument('-it', '--interactive-tty', action='store_true', help='äº¤äº’å¼è¿è¡Œå®¹å™¨ (åˆ†é…ä¼ªTTYå¹¶ä¿æŒstdinæ‰“å¼€)')
    run_parser.add_argument('-e', '--env', action='append', default=[], help='ç¯å¢ƒå˜é‡ (KEY=VALUE)')
    run_parser.add_argument('-v', '--volume', dest='bind', action='append', default=[], help='æŒ‚è½½å· (HOST:CONTAINER)')
    run_parser.add_argument('-w', '--workdir', help='å·¥ä½œç›®å½•')
    run_parser.add_argument('--force-download', action='store_true', help='å¼ºåˆ¶é‡æ–°ä¸‹è½½é•œåƒ')

    # start å‘½ä»¤
    start_parser = subparsers.add_parser('start', help='å¯åŠ¨ä¸€ä¸ªå·²åœæ­¢çš„å®¹å™¨')
    start_parser.add_argument('container', help='å®¹å™¨ID')

    # restart å‘½ä»¤
    restart_parser = subparsers.add_parser('restart', help='é‡å¯ä¸€ä¸ªå®¹å™¨')
    restart_parser.add_argument('container', help='å®¹å™¨ID')

    # ps å‘½ä»¤
    ps_parser = subparsers.add_parser('ps', help='åˆ—å‡ºå®¹å™¨')
    ps_parser.add_argument('-a', '--all', action='store_true', help='æ˜¾ç¤ºæ‰€æœ‰å®¹å™¨ï¼ˆåŒ…æ‹¬å·²åœæ­¢çš„ï¼‰')

    # logs å‘½ä»¤
    logs_parser = subparsers.add_parser('logs', help='æŸ¥çœ‹å®¹å™¨æ—¥å¿—')
    logs_parser.add_argument('container', help='å®¹å™¨ID')
    logs_parser.add_argument('-f', '--follow', action='store_true', help='æŒç»­è¾“å‡ºæ—¥å¿—')

    # images å‘½ä»¤
    subparsers.add_parser('images', help='åˆ—å‡ºé•œåƒ')

    # rmi å‘½ä»¤
    rmi_parser = subparsers.add_parser('rmi', help='åˆ é™¤é•œåƒ')
    rmi_parser.add_argument('image', help='é•œåƒURL')

    # stop å‘½ä»¤
    stop_parser = subparsers.add_parser('stop', help='åœæ­¢å®¹å™¨')
    stop_parser.add_argument('container', help='å®¹å™¨ID')

    # rm å‘½ä»¤
    rm_parser = subparsers.add_parser('rm', help='åˆ é™¤å®¹å™¨')
    rm_parser.add_argument('container', help='å®¹å™¨ID')
    rm_parser.add_argument('-f', '--force', action='store_true', help='å¼ºåˆ¶åˆ é™¤è¿è¡Œä¸­çš„å®¹å™¨')
    
    # attach å‘½ä»¤
    attach_parser = subparsers.add_parser('attach', help='é™„åŠ åˆ°è¿è¡Œä¸­çš„å®¹å™¨å¹¶æŸ¥çœ‹è¾“å‡º')
    attach_parser.add_argument('container', help='å®¹å™¨ID')
    
    # exec å‘½ä»¤
    exec_parser = subparsers.add_parser('exec', help='åœ¨è¿è¡Œä¸­çš„å®¹å™¨ä¸­æ‰§è¡Œå‘½ä»¤')
    exec_parser.add_argument('container', help='å®¹å™¨ID')
    exec_parser.add_argument('command', nargs='*', help='è¦æ‰§è¡Œçš„å‘½ä»¤')
    exec_parser.add_argument('-it', '--interactive-tty', action='store_true', help='äº¤äº’å¼è¿è¡Œå®¹å™¨ (åˆ†é…ä¼ªTTYå¹¶ä¿æŒstdinæ‰“å¼€)')

    # build å‘½ä»¤
    build_parser = subparsers.add_parser('build', help='æ„å»ºDockeré•œåƒ')
    build_parser.add_argument('context', help='æ„å»ºä¸Šä¸‹æ–‡è·¯å¾„')
    build_parser.add_argument('-t', '--tag', help='é•œåƒæ ‡ç­¾')
    build_parser.add_argument('-f', '--file', help='Dockerfileè·¯å¾„')

    # save å‘½ä»¤
    save_parser = subparsers.add_parser('save', help='ä¿å­˜é•œåƒåˆ°taræ–‡ä»¶')
    save_parser.add_argument('image', help='é•œåƒåç§°')
    save_parser.add_argument('-o', '--output', required=True, help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')

    # load å‘½ä»¤
    load_parser = subparsers.add_parser('load', help='ä»taræ–‡ä»¶åŠ è½½é•œåƒ')
    load_parser.add_argument('-i', '--input', required=True, help='è¾“å…¥æ–‡ä»¶è·¯å¾„')

    # tag å‘½ä»¤
    tag_parser = subparsers.add_parser('tag', help='ä¸ºé•œåƒæ·»åŠ æ ‡ç­¾')
    tag_parser.add_argument('source_image', help='æºé•œåƒ')
    tag_parser.add_argument('target_image', help='ç›®æ ‡é•œåƒ')

    # inspect å‘½ä»¤
    inspect_parser = subparsers.add_parser('inspect', help='æ£€æŸ¥å®¹å™¨æˆ–é•œåƒçš„è¯¦ç»†ä¿¡æ¯')
    inspect_parser.add_argument('target', help='å®¹å™¨IDæˆ–é•œåƒåç§°')

    # top å‘½ä»¤
    top_parser = subparsers.add_parser('top', help='æ˜¾ç¤ºå®¹å™¨ä¸­è¿è¡Œçš„è¿›ç¨‹')
    top_parser.add_argument('container', help='å®¹å™¨ID')

    # stats å‘½ä»¤
    stats_parser = subparsers.add_parser('stats', help='æ˜¾ç¤ºå®¹å™¨çš„èµ„æºä½¿ç”¨ç»Ÿè®¡')
    stats_parser.add_argument('container', nargs='?', help='å®¹å™¨ID (å¯é€‰ï¼Œä¸æŒ‡å®šåˆ™æ˜¾ç¤ºæ‰€æœ‰å®¹å™¨)')

    # cp å‘½ä»¤
    cp_parser = subparsers.add_parser('cp', help='åœ¨å®¹å™¨å’Œä¸»æœºä¹‹é—´å¤åˆ¶æ–‡ä»¶')
    cp_parser.add_argument('source', help='æºè·¯å¾„')
    cp_parser.add_argument('dest', help='ç›®æ ‡è·¯å¾„')

    # diff å‘½ä»¤
    diff_parser = subparsers.add_parser('diff', help='æ˜¾ç¤ºå®¹å™¨æ–‡ä»¶ç³»ç»Ÿçš„å˜æ›´')
    diff_parser.add_argument('container', help='å®¹å™¨ID')

    # commit å‘½ä»¤
    commit_parser = subparsers.add_parser('commit', help='ä»å®¹å™¨åˆ›å»ºæ–°é•œåƒ')
    commit_parser.add_argument('container', help='å®¹å™¨ID')
    commit_parser.add_argument('repository', help='é•œåƒä»“åº“åç§°')
    commit_parser.add_argument('tag', nargs='?', default='latest', help='é•œåƒæ ‡ç­¾ (é»˜è®¤: latest)')

    # export å‘½ä»¤
    export_parser = subparsers.add_parser('export', help='å¯¼å‡ºå®¹å™¨æ–‡ä»¶ç³»ç»Ÿåˆ°taræ–‡ä»¶')
    export_parser.add_argument('container', help='å®¹å™¨ID')
    export_parser.add_argument('-o', '--output', required=True, help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')

    # import å‘½ä»¤
    import_parser = subparsers.add_parser('import', help='ä»taræ–‡ä»¶å¯¼å…¥é•œåƒ')
    import_parser.add_argument('file', help='taræ–‡ä»¶è·¯å¾„')
    import_parser.add_argument('repository', help='é•œåƒä»“åº“åç§°')
    import_parser.add_argument('tag', nargs='?', default='latest', help='é•œåƒæ ‡ç­¾ (é»˜è®¤: latest)')

    # history å‘½ä»¤
    history_parser = subparsers.add_parser('history', help='æ˜¾ç¤ºé•œåƒçš„å†å²è®°å½•')
    history_parser.add_argument('image', help='é•œåƒåç§°')

    # info å‘½ä»¤
    subparsers.add_parser('info', help='æ˜¾ç¤ºç³»ç»Ÿä¿¡æ¯')

    # version å‘½ä»¤
    subparsers.add_parser('version', help='æ˜¾ç¤ºç‰ˆæœ¬ä¿¡æ¯')

    # help å‘½ä»¤
    help_parser = subparsers.add_parser('help', help='æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯')
    help_parser.add_argument('command', nargs='?', help='è¦æ˜¾ç¤ºå¸®åŠ©çš„å‘½ä»¤')

    # network å‘½ä»¤ç»„
    network_parser = subparsers.add_parser('network', help='ç½‘ç»œç®¡ç†')
    network_subparsers = network_parser.add_subparsers(dest='network_command', required=True)
    
    network_create_parser = network_subparsers.add_parser('create', help='åˆ›å»ºç½‘ç»œ')
    network_create_parser.add_argument('name', help='ç½‘ç»œåç§°')
    network_create_parser.add_argument('--driver', default='bridge', help='ç½‘ç»œé©±åŠ¨ (é»˜è®¤: bridge)')
    
    network_subparsers.add_parser('ls', help='åˆ—å‡ºç½‘ç»œ')
    
    network_rm_parser = network_subparsers.add_parser('rm', help='åˆ é™¤ç½‘ç»œ')
    network_rm_parser.add_argument('name', help='ç½‘ç»œåç§°')

    # volume å‘½ä»¤ç»„
    volume_parser = subparsers.add_parser('volume', help='å·ç®¡ç†')
    volume_subparsers = volume_parser.add_subparsers(dest='volume_command', required=True)
    
    volume_create_parser = volume_subparsers.add_parser('create', help='åˆ›å»ºå·')
    volume_create_parser.add_argument('name', help='å·åç§°')
    
    volume_subparsers.add_parser('ls', help='åˆ—å‡ºå·')
    
    volume_rm_parser = volume_subparsers.add_parser('rm', help='åˆ é™¤å·')
    volume_rm_parser.add_argument('name', help='å·åç§°')

    # system å‘½ä»¤ç»„
    system_parser = subparsers.add_parser('system', help='ç³»ç»Ÿç®¡ç†')
    system_subparsers = system_parser.add_subparsers(dest='system_command', required=True)
    
    system_prune_parser = system_subparsers.add_parser('prune', help='æ¸…ç†æœªä½¿ç”¨çš„èµ„æº')
    system_prune_parser.add_argument('-a', '--all', action='store_true', help='æ¸…ç†æ‰€æœ‰æœªä½¿ç”¨çš„èµ„æº')

    return parser

def main():
    """ä¸»å‡½æ•°"""
    parser = create_parser()
    args, unknown = parser.parse_known_args()

    # Handle the command part for 'run' and 'exec'
    if args.subcommand in ['run', 'exec']:
        # Combine the command parts that argparse might have split.
        # `args.command` will have any command parts found before an unknown option.
        # `unknown` will have any arguments that were not recognized.
        # For `run` and `exec`, these are part of the command to be executed.
        args.command.extend(unknown)
    elif unknown:
        # For other subcommands, unknown arguments are an error.
        parser.error(f"unrecognized arguments: {' '.join(unknown)}")

    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)

    # å¦‚æœæ²¡æœ‰æŒ‡å®šå‘½ä»¤ï¼Œæ˜¾ç¤ºå¸®åŠ©
    if not args.subcommand:
        parser.print_help()
        return

    # åˆ›å»ºCLIå®ä¾‹
    cli = DockerCLI(cache_dir=args.cache_dir)

    try:
        if args.subcommand == 'login':
            success = cli.login(args.server, args.username, args.password)
            sys.exit(0 if success else 1)

        elif args.subcommand == 'pull':
            success = cli.pull(args.image, force=args.force, quiet=args.quiet)
            sys.exit(0 if success else 1)

        elif args.subcommand == 'push':
            success = cli.push(args.image, args.tag)
            sys.exit(0 if success else 1)

        elif args.subcommand == 'run':
            # åœ¨è°ƒç”¨runä¹‹å‰åŠ è½½å‡­è¯å¹¶é™„åŠ åˆ°kwargs
            config = cli._load_config()
            auths = config.get('auths', {})
            username, password = None, None
            for server, creds in auths.items():
                server_name = urlparse(server).hostname or server
                if server_name in args.image or (server_name == "index.docker.io" and '/' not in args.image.split(':')[0]):
                    username = creds.get('username')
                    password = creds.get('password')
                    break
            
            container_id = cli.run(
                args.image,
                command=args.command,
                name=args.name,
                env=args.env,
                bind=args.bind,
                workdir=args.workdir,
                detach=args.detach,
                interactive=args.interactive_tty,
                force_download=args.force_download,
                username=username,
                password=password
            )
            sys.exit(0 if container_id else 1)

        elif args.subcommand == 'start':
            success = cli.start(args.container)
            sys.exit(0 if success else 1)

        elif args.subcommand == 'restart':
            success = cli.restart(args.container)
            sys.exit(0 if success else 1)

        elif args.subcommand == 'ps':
            cli.ps(all_containers=args.all)

        elif args.subcommand == 'logs':
            success = cli.logs(args.container, follow=args.follow)
            sys.exit(0 if success else 1)

        elif args.subcommand == 'images':
            cli.images()

        elif args.subcommand == 'rmi':
            success = cli.rmi(args.image)
            sys.exit(0 if success else 1)

        elif args.subcommand == 'stop':
            success = cli.stop(args.container)
            sys.exit(0 if success else 1)

        elif args.subcommand == 'rm':
            success = cli.rm(args.container, force=args.force)
            sys.exit(0 if success else 1)
            
        elif args.subcommand == 'attach':
            success = cli.attach(args.container)
            sys.exit(0 if success else 1)
            
        elif args.subcommand == 'exec':
            success = cli.exec(args.container, args.command, interactive=args.interactive_tty)
            sys.exit(0 if success else 1)

        elif args.subcommand == 'build':
            success = cli.build(args.context, args.tag, args.file)
            sys.exit(0 if success else 1)

        elif args.subcommand == 'save':
            success = cli.save(args.image, args.output)
            sys.exit(0 if success else 1)

        elif args.subcommand == 'load':
            success = cli.load(args.input)
            sys.exit(0 if success else 1)

        elif args.subcommand == 'tag':
            success = cli.tag(args.source_image, args.target_image)
            sys.exit(0 if success else 1)

        elif args.subcommand == 'inspect':
            success = cli.inspect(args.target)
            sys.exit(0 if success else 1)

        elif args.subcommand == 'top':
            success = cli.top(args.container)
            sys.exit(0 if success else 1)

        elif args.subcommand == 'stats':
            success = cli.stats(args.container)
            sys.exit(0 if success else 1)

        elif args.subcommand == 'cp':
            success = cli.cp(args.source, args.dest)
            sys.exit(0 if success else 1)

        elif args.subcommand == 'diff':
            success = cli.diff(args.container)
            sys.exit(0 if success else 1)

        elif args.subcommand == 'commit':
            success = cli.commit(args.container, args.repository, args.tag)
            sys.exit(0 if success else 1)

        elif args.subcommand == 'export':
            success = cli.export(args.container, args.output)
            sys.exit(0 if success else 1)

        elif args.subcommand == 'import':
            success = cli.import_(args.file, args.repository, args.tag)
            sys.exit(0 if success else 1)

        elif args.subcommand == 'history':
            success = cli.history(args.image)
            sys.exit(0 if success else 1)

        elif args.subcommand == 'info':
            success = cli.info()
            sys.exit(0 if success else 1)

        elif args.subcommand == 'version':
            success = cli.version()
            sys.exit(0 if success else 1)

        elif args.subcommand == 'help':
            success = cli.help(args.command)
            sys.exit(0 if success else 1)

        elif args.subcommand == 'network':
            if args.network_command == 'create':
                success = cli.network_create(args.name, args.driver)
            elif args.network_command == 'ls':
                success = cli.network_ls()
            elif args.network_command == 'rm':
                success = cli.network_rm(args.name)
            else:
                logger.error(f"æœªçŸ¥çš„ç½‘ç»œå‘½ä»¤: {args.network_command}")
                success = False
            sys.exit(0 if success else 1)

        elif args.subcommand == 'volume':
            if args.volume_command == 'create':
                success = cli.volume_create(args.name)
            elif args.volume_command == 'ls':
                success = cli.volume_ls()
            elif args.volume_command == 'rm':
                success = cli.volume_rm(args.name)
            else:
                logger.error(f"æœªçŸ¥çš„å·å‘½ä»¤: {args.volume_command}")
                success = False
            sys.exit(0 if success else 1)

        elif args.subcommand == 'system':
            if args.system_command == 'prune':
                success = cli.system_prune(args.all)
            else:
                logger.error(f"æœªçŸ¥çš„ç³»ç»Ÿå‘½ä»¤: {args.system_command}")
                success = False
            sys.exit(0 if success else 1)

        else:
            logger.error(f"æœªçŸ¥å‘½ä»¤: {args.subcommand}")
            parser.print_help()
            sys.exit(1)

    except KeyboardInterrupt:
        logger.info("ç”¨æˆ·ä¸­æ–­")
        sys.exit(130)
    except Exception as e:
        logger.error(f"æ‰§è¡Œå¤±è´¥: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        sys.exit(1)

if __name__ == '__main__':
    main()
